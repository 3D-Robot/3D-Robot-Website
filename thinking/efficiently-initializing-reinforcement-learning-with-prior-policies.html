<!DOCTYPE html><html lang="en">
<!-- Mirrored from everydayrobots.com/thinking/efficiently-initializing-reinforcement-learning-with-prior-policies by HTTrack Website Copier/3.x [XR&CO'2014], Mon, 16 May 2022 06:47:12 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head><link rel="apple-touch-icon" sizes="180x180" href="../static/favicon/apple-touch-icon.png"/><link rel="icon" href="../static/favicon/favicon.svg" type="image/svg+xml"/><link rel="icon" type="image/png" sizes="32x32" href="../static/favicon/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="../static/favicon/favicon-16x16.png"/><link rel="manifest" href="../static/favicon/site.webmanifest"/><meta name="msapplication-TileColor" content="#ffad00"/><meta name="theme-color" content="#ffffff"/><link rel="preload" href="../static/fonts/calibre/calibre-web-medium.woff2" as="font" type="font/woff2" crossorigin=""/><link rel="preload" href="../static/fonts/calibre/calibre-web-semibold.woff2" as="font" type="font/woff2" crossorigin=""/><link rel="preload" href="../static/fonts/calibre/calibre-web-regular.woff2" as="font" type="font/woff2" crossorigin=""/><link href="https://fonts.googleapis.com/css2?family=Source+Serif+Pro:ital@0;1&amp;display=swap" rel="stylesheet"/><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><title>Efficiently Initializing Reinforcement Learning With Prior Policies | Everyday Robots</title><meta name="description" content="Born from X, and working alongside teams at Google, we’re building a new type of robot. One that can learn by itself, to help anyone with (almost) anything."/><link rel="canonical" href="efficiently-initializing-reinforcement-learning-with-prior-policies.html"/><meta property="og:type" content="website"/><meta property="og:url" content="efficiently-initializing-reinforcement-learning-with-prior-policies.html"/><meta property="og:title" content="Efficiently Initializing Reinforcement Learning With Prior Policies | Everyday Robots"/><meta property="og:description" content="Born from X, and working alongside teams at Google, we’re building a new type of robot. One that can learn by itself, to help anyone with (almost) anything."/><meta property="og:image" content="../../images.ctfassets.net/1ejv5e8uweut/4hO9HJ5AyTzOSwQlzIEnky/b86362c044cc324535fb7e1112c10b07/20210722-DSCF0126Peter-Prato__2_.jpg"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="Robot sorting in real and sim "/><meta property="og:site_name" content="Everyday Robots"/><meta property="og:locale" content="en_US"/><meta name="twitter:card" content="summary_large_image"/><meta name="next-head-count" content="16"/><link rel="preload" href="../_next/static/css/cb3d4f9cd14b1d37.css" as="style"/><link rel="stylesheet" href="../_next/static/css/cb3d4f9cd14b1d37.css" data-n-g=""/><link rel="preload" href="../_next/static/css/447c4556f3bf7bd6.css" as="style"/><link rel="stylesheet" href="../_next/static/css/447c4556f3bf7bd6.css" data-n-p=""/><noscript data-n-css=""></noscript><script nonce="qqZu5p16uR" defer="" nomodule="" src="../_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script nonce="qqZu5p16uR" src="../_next/static/chunks/webpack-5752944655d749a0.js" defer=""></script><script nonce="qqZu5p16uR" src="../_next/static/chunks/framework-dc33c0b5493501f0.js" defer=""></script><script nonce="qqZu5p16uR" src="../_next/static/chunks/main-c35ee0b11b2b060c.js" defer=""></script><script nonce="qqZu5p16uR" src="../_next/static/chunks/pages/_app-8571796ae56338f4.js" defer=""></script><script nonce="qqZu5p16uR" src="../_next/static/chunks/67-dc76cec621442723.js" defer=""></script><script nonce="qqZu5p16uR" src="../_next/static/chunks/208-12bdec0f5ab636f5.js" defer=""></script><script nonce="qqZu5p16uR" src="../_next/static/chunks/885-2eb7ca6f0661e01f.js" defer=""></script><script nonce="qqZu5p16uR" src="../_next/static/chunks/623-1feb071639199466.js" defer=""></script><script nonce="qqZu5p16uR" src="../_next/static/chunks/509-b2d12cc9757db62d.js" defer=""></script><script nonce="qqZu5p16uR" src="../_next/static/chunks/329-77a38873a8d5edc0.js" defer=""></script><script nonce="qqZu5p16uR" src="../_next/static/chunks/pages/thinking/%5bslug%5d-67f6e1d03e60eff1.js" defer=""></script><script nonce="qqZu5p16uR" src="../_next/static/ZF09WpqHefixs7Zvyw-nn/_buildManifest.js" defer=""></script><script nonce="qqZu5p16uR" src="../_next/static/ZF09WpqHefixs7Zvyw-nn/_ssgManifest.js" defer=""></script><script nonce="qqZu5p16uR" src="../_next/static/ZF09WpqHefixs7Zvyw-nn/_middlewareManifest.js" defer=""></script><style data-styled="" data-styled-version="5.3.5">.hbJg{width:max(15px,0.25rem);height:max(15px,0.25rem);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;place-items:center;place-content:center;}/*!sc*/
.jXynWI{width:max(20px,0.3333333333333333rem);height:max(20px,0.3333333333333333rem);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;place-items:center;place-content:center;}/*!sc*/
.cBpQkk{width:max(18px,0.3rem);height:max(18px,0.3rem);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;place-items:center;place-content:center;}/*!sc*/
.kYodSY{width:max(12px,0.2rem);height:max(12px,0.2rem);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;place-items:center;place-content:center;}/*!sc*/
data-styled.g1[id="sc-faf29a58-0"]{content:"hbJg,jXynWI,cBpQkk,kYodSY,"}/*!sc*/
.gLPuKv{-webkit-transform:rotate(270deg);-ms-transform:rotate(270deg);transform:rotate(270deg);}/*!sc*/
.gLPuKv > path{fill:#000000;}/*!sc*/
data-styled.g2[id="sc-cbc7a3bd-0"]{content:"gLPuKv,"}/*!sc*/
.ZkFrP{height:max(40px,0.6666666666666666rem);-webkit-transition:fill 0.25s cubic-bezier(0.6,0,0.2,1);transition:fill 0.25s cubic-bezier(0.6,0,0.2,1);}/*!sc*/
@media (min-width:48em){.ZkFrP{height:max(50px,0.8333333333333334rem);}}/*!sc*/
data-styled.g4[id="sc-147f2498-0"]{content:"ZkFrP,"}/*!sc*/
.gGvOxe{opacity:0;}/*!sc*/
.gGvOxe[data-loaded='true']{-webkit-animation:hbjThv 0.6s cubic-bezier(0.2,0.85,0.45,1) forwards;animation:hbjThv 0.6s cubic-bezier(0.2,0.85,0.45,1) forwards;}/*!sc*/
data-styled.g6[id="sc-f59e9df7-0"]{content:"gGvOxe,"}/*!sc*/
.iaNrAz{width:100%;object-fit:cover;height:100%;opacity:0;}/*!sc*/
.iaNrAz[data-loaded='true']{-webkit-animation:hbjThv 0.6s cubic-bezier(0.2,0.85,0.45,1) forwards;animation:hbjThv 0.6s cubic-bezier(0.2,0.85,0.45,1) forwards;}/*!sc*/
data-styled.g7[id="sc-f59e9df7-1"]{content:"iaNrAz,"}/*!sc*/
.eglMLr{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;overflow:hidden;border-radius:4px;aspect-ratio:3 / 2;width:100%;position:relative;}/*!sc*/
@supports not (aspect-ratio:auto){.eglMLr:after{content:'';display:block;padding-bottom:66.66666666666666%;}}/*!sc*/
.eglMLr > .sc-f59e9df7-0 > *,.eglMLr > .sc-f59e9df7-1 > *{position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;border-radius:4px;}/*!sc*/
.eglMLr > .sc-f59e9df7-0 > *,.eglMLr > .sc-f59e9df7-1 > *{border-radius:4px;}/*!sc*/
.YtoQn{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;overflow:hidden;border-radius:4px;}/*!sc*/
.YtoQn > .sc-f59e9df7-0 > *,.YtoQn > .sc-f59e9df7-1 > *{width:100%;height:100%;border-radius:4px;}/*!sc*/
.cyoGde{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;overflow:hidden;border-radius:4px;aspect-ratio:64 / 31;width:100%;position:relative;}/*!sc*/
@supports not (aspect-ratio:auto){.cyoGde:after{content:'';display:block;padding-bottom:48.4375%;}}/*!sc*/
.cyoGde > .sc-f59e9df7-0 > *,.cyoGde > .sc-f59e9df7-1 > *{position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;border-radius:4px;}/*!sc*/
.iRHovN{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;overflow:hidden;border-radius:4px;aspect-ratio:64 / 33;width:100%;position:relative;}/*!sc*/
@supports not (aspect-ratio:auto){.iRHovN:after{content:'';display:block;padding-bottom:51.5625%;}}/*!sc*/
.iRHovN > .sc-f59e9df7-0 > *,.iRHovN > .sc-f59e9df7-1 > *{position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;border-radius:4px;}/*!sc*/
.jsrTEH{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;overflow:hidden;border-radius:4px;aspect-ratio:64 / 53;width:100%;position:relative;}/*!sc*/
@supports not (aspect-ratio:auto){.jsrTEH:after{content:'';display:block;padding-bottom:82.8125%;}}/*!sc*/
.jsrTEH > .sc-f59e9df7-0 > *,.jsrTEH > .sc-f59e9df7-1 > *{position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;border-radius:4px;}/*!sc*/
data-styled.g8[id="sc-f59e9df7-2"]{content:"eglMLr,YtoQn,cyoGde,iRHovN,jsrTEH,"}/*!sc*/
.gnODzT{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:max(15px,0.25rem);}/*!sc*/
data-styled.g9[id="sc-93a65f79-0"]{content:"gnODzT,"}/*!sc*/
.jZunqb{margin:0 0 max(15px,0.25rem);font-family:'Source Serif Pro',serif;color:#262626;font-size:max(12px,0.64rem);line-height:1.0666666666666667rem;-webkit-letter-spacing:-0.014506666666666668rem;-moz-letter-spacing:-0.014506666666666668rem;-ms-letter-spacing:-0.014506666666666668rem;letter-spacing:-0.014506666666666668rem;}/*!sc*/
@media (min-width:48em){.jZunqb{font-size:max(12px,0.29296875rem);line-height:0.48828125rem;-webkit-letter-spacing:-0.006640625rem;-moz-letter-spacing:-0.006640625rem;-ms-letter-spacing:-0.006640625rem;letter-spacing:-0.006640625rem;}}/*!sc*/
@media (min-width:64.0625em){.jZunqb{font-size:max(12px,0.25rem);line-height:0.4166666666666667rem;-webkit-letter-spacing:-0.005666666666666667rem;-moz-letter-spacing:-0.005666666666666667rem;-ms-letter-spacing:-0.005666666666666667rem;letter-spacing:-0.005666666666666667rem;}}/*!sc*/
.edIRpA{margin:0 0 max(15px,0.25rem);font-family:'Source Serif Pro',serif;color:#262626;font-size:max(14px,0.7253333333333334rem);line-height:1.28rem;-webkit-letter-spacing:-0.017066666666666667rem;-moz-letter-spacing:-0.017066666666666667rem;-ms-letter-spacing:-0.017066666666666667rem;letter-spacing:-0.017066666666666667rem;}/*!sc*/
@media (min-width:48em){.edIRpA{font-size:max(14px,0.33203125rem);line-height:0.5rem;-webkit-letter-spacing:-0.0078125rem;-moz-letter-spacing:-0.0078125rem;-ms-letter-spacing:-0.0078125rem;letter-spacing:-0.0078125rem;}}/*!sc*/
@media (min-width:64.0625em){.edIRpA{font-size:max(14px,0.2833333333333333rem);line-height:0.5rem;-webkit-letter-spacing:-0.006666666666666667rem;-moz-letter-spacing:-0.006666666666666667rem;-ms-letter-spacing:-0.006666666666666667rem;letter-spacing:-0.006666666666666667rem;}}/*!sc*/
.imkcGb{margin:0 0 max(15px,0.25rem);font-size:max(12px,0.5973333333333334rem);line-height:max(12px,0.5973333333333334rem);}/*!sc*/
@media (min-width:48em){.imkcGb{font-size:max(12px,0.2734375rem);line-height:max(12px,0.2734375rem);}}/*!sc*/
@media (min-width:64.0625em){.imkcGb{font-size:max(12px,0.23333333333333334rem);line-height:max(12px,0.23333333333333334rem);}}/*!sc*/
data-styled.g10[id="sc-d57e93a-0"]{content:"jZunqb,edIRpA,imkcGb,"}/*!sc*/
.bCAHtX{overflow:hidden;opacity:1 !important;pointer-events:all !important;}/*!sc*/
data-styled.g12[id="sc-f641962e-0"]{content:"bCAHtX,"}/*!sc*/
html{font-family:'Calibre',sans-serif;font-weight:500;background:#ede8e6;box-sizing:border-box;-webkit-font-smoothing:antialiased;font-size:6.25vw;}/*!sc*/
@media (min-width:48em){html{font-size:5vw;}}/*!sc*/
@media (min-width:64.0625em){html{font-size:4.166666666666667vw;}}/*!sc*/
html.has-grid-overlay:before{content:'MOBILE - 16 COLUMNS';position:fixed;top:4px;left:4px;font-size:12px;line-height:12px;font-weight:600;color:#ee474780;-webkit-writing-mode:vertical-rl;-ms-writing-mode:tb-rl;writing-mode:vertical-rl;}/*!sc*/
@media (min-width:48em){html.has-grid-overlay:before{content:'TABLET - 20 COLUMNS';}}/*!sc*/
@media (min-width:64.0625em){html.has-grid-overlay:before{content:'DESKTOP - 24 COLUMNS';}}/*!sc*/
html.has-grid-overlay:after{content:'';position:fixed;top:0;right:0;left:0;bottom:0;background-image:linear-gradient( to right, #ee47474d 1px, transparent 0 );background-size:calc(100% / 16);}/*!sc*/
@media (min-width:48em){html.has-grid-overlay:after{background-size:calc(100% / 20);}}/*!sc*/
@media (min-width:64.0625em){html.has-grid-overlay:after{background-size:calc(100% / 24);}}/*!sc*/
html.has-grid-overlay:before,html.has-grid-overlay:after{z-index:9;pointer-events:none;}/*!sc*/
body{margin:0;}/*!sc*/
*,*:before,*:after{box-sizing:inherit;-webkit-tap-highlight-color:transparent;}/*!sc*/
*::selection{background:#ffad004d;}/*!sc*/
body #cookieBar{background:transparent;right:max(15px,0.25rem);bottom:max(15px,0.25rem);left:max(15px,0.25rem);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-animation:hUniol 0.25s cubic-bezier(0.6,0,0.2,1) forwards;animation:hUniol 0.25s cubic-bezier(0.6,0,0.2,1) forwards;width:auto;}/*!sc*/
body #cookieBar > .cookieBarInner{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;background-color:#ffffff;color:#000000;border-radius:4px;padding:max(10px,0.16666666666666666rem) max(25px,0.4166666666666667rem);}/*!sc*/
body #cookieBar > .cookieBarInner > .cookieBarText,body #cookieBar > .cookieBarInner > .cookieBarButtons{font-family:'Calibre',sans-serif;font-size:max(12px,0.5973333333333334rem);line-height:max(12px,0.5973333333333334rem);font-weight:400;}/*!sc*/
@media (min-width:48em){body #cookieBar > .cookieBarInner > .cookieBarText,body #cookieBar > .cookieBarInner > .cookieBarButtons{font-size:max(12px,0.2734375rem);line-height:max(12px,0.2734375rem);}}/*!sc*/
@media (min-width:64.0625em){body #cookieBar > .cookieBarInner > .cookieBarText,body #cookieBar > .cookieBarInner > .cookieBarButtons{font-size:max(12px,0.23333333333333334rem);line-height:max(12px,0.23333333333333334rem);}}/*!sc*/
body #cookieBar > .cookieBarInner > .cookieBarText,body #cookieBar > .cookieBarInner > .cookieBarButtons > .cookieBarButton{margin:max(5px,0.08333333333333333rem) max(15px,0.25rem);}/*!sc*/
body #cookieBar > .cookieBarInner > .cookieBarText{text-align:center;}/*!sc*/
body #cookieBar > .cookieBarInner > .cookieBarButtons{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/
body #cookieBar > .cookieBarInner > .cookieBarButtons > .cookieBarButton{background:transparent;color:#000000;border:1px solid #00000033;padding:max(10px,0.16666666666666666rem) max(15px,0.25rem);border-radius:4px;-webkit-transition:border-color 0.25s cubic-bezier(0.6,0,0.2,1);transition:border-color 0.25s cubic-bezier(0.6,0,0.2,1);line-height:inherit;}/*!sc*/
body #cookieBar > .cookieBarInner > .cookieBarButtons > .cookieBarButton:first-child{margin-right:0;}/*!sc*/
body #cookieBar > .cookieBarInner > .cookieBarButtons > .cookieBarButton:focus{outline:1px solid #ffad00;outline-offset:4px;}/*!sc*/
body #cookieBar > .cookieBarInner > .cookieBarButtons > .cookieBarButton:focus:not(:focus-visible){outline:0;}/*!sc*/
body #cookieBar > .cookieBarInner > .cookieBarButtons > .cookieBarButton:hover{border-color:#000000;}/*!sc*/
html.has-scroll-smooth{overflow:hidden;position:fixed;top:0;right:0;bottom:0;left:0;}/*!sc*/
html.has-scroll-dragging{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;}/*!sc*/
.has-scroll-smooth body{overflow:hidden;}/*!sc*/
.has-scroll-smooth [data-scroll-container]{min-height:100vh;}/*!sc*/
[data-scroll-direction='horizontal'] [data-scroll-container]{height:100vh;display:inline-block;white-space:nowrap;}/*!sc*/
[data-scroll-direction='horizontal'] [data-scroll-section]{display:inline-block;vertical-align:top;white-space:nowrap;height:100%;}/*!sc*/
.c-scrollbar{position:absolute;right:0;top:0;width:11px;height:100%;-webkit-transform-origin:center right;-ms-transform-origin:center right;transform-origin:center right;-webkit-transition:0.25s;transition:0.25s;-webkit-transition-property:-webkit-transform,opacity;-webkit-transition-property:transform,opacity;transition-property:transform,opacity;opacity:0;z-index:1;}/*!sc*/
.c-scrollbar:hover{-webkit-transform:scaleX(1.45);-ms-transform:scaleX(1.45);transform:scaleX(1.45);}/*!sc*/
.c-scrollbar:hover,.has-scroll-scrolling .c-scrollbar,.has-scroll-dragging .c-scrollbar{opacity:1;}/*!sc*/
[data-scroll-direction='horizontal'] .c-scrollbar{width:100%;height:10px;top:auto;bottom:0;-webkit-transform:scaleY(1);-ms-transform:scaleY(1);transform:scaleY(1);}/*!sc*/
[data-scroll-direction='horizontal'] .c-scrollbar:hover{-webkit-transform:scaleY(1.2);-ms-transform:scaleY(1.2);transform:scaleY(1.2);}/*!sc*/
.c-scrollbar_thumb{position:absolute;top:0;right:0;background-color:#000000;opacity:0.5;width:7px;border-radius:10px;margin:2px;cursor:-webkit-grab;cursor:-moz-grab;cursor:grab;-webkit-transition:height 0.6s cubic-bezier(0.2,0.85,0.45,1), -webkit-transform 0.25s cubic-bezier(0.2,0.85,0.45,1);-webkit-transition:height 0.6s cubic-bezier(0.2,0.85,0.45,1), transform 0.25s cubic-bezier(0.2,0.85,0.45,1);transition:height 0.6s cubic-bezier(0.2,0.85,0.45,1), transform 0.25s cubic-bezier(0.2,0.85,0.45,1);}/*!sc*/
.has-scroll-dragging .c-scrollbar_thumb{cursor:-webkit-grabbing;cursor:-moz-grabbing;cursor:grabbing;}/*!sc*/
[data-scroll-direction='horizontal'] .c-scrollbar_thumb{right:auto;bottom:0;}/*!sc*/
data-styled.g13[id="sc-global-jqcLrp1"]{content:"sc-global-jqcLrp1,"}/*!sc*/
.jUoqXe{display:none;}/*!sc*/
@media (min-width:48em){@media (pointer:fine){.jUoqXe{position:fixed;top:0;left:0;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;z-index:7;pointer-events:none;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-transition:-webkit-transform 0.4s cubic-bezier(0.2,0.85,0.45,1);-webkit-transition:transform 0.4s cubic-bezier(0.2,0.85,0.45,1);transition:transform 0.4s cubic-bezier(0.2,0.85,0.45,1);will-change:transform;}}}/*!sc*/
data-styled.g14[id="sc-efd73938-0"]{content:"jUoqXe,"}/*!sc*/
.laHiNe{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/
.laHiNe:focus{outline:1px solid #ffad00;outline-offset:4px;}/*!sc*/
.laHiNe:focus:not(:focus-visible){outline:0;}/*!sc*/
data-styled.g17[id="sc-37c0da59-0"]{content:"laHiNe,"}/*!sc*/
.tqmXq{-webkit-text-decoration:none;text-decoration:none;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-radius:50%;padding:0;background:#ffffff;width:max(60px,1rem);height:max(60px,1rem);-webkit-flex:none;-ms-flex:none;flex:none;-webkit-transition:background 0.25s cubic-bezier(0.6,0,0.2,1);transition:background 0.25s cubic-bezier(0.6,0,0.2,1);}/*!sc*/
.tqmXq:focus{outline:1px solid #ffad00;outline-offset:4px;}/*!sc*/
.tqmXq:focus:not(:focus-visible){outline:0;}/*!sc*/
.tqmXq > .icon-wrapper > svg{-webkit-flex:none;-ms-flex:none;flex:none;-webkit-transition:-webkit-transform 0.25s cubic-bezier(0.6,0,0.2,1);-webkit-transition:transform 0.25s cubic-bezier(0.6,0,0.2,1);transition:transform 0.25s cubic-bezier(0.6,0,0.2,1);}/*!sc*/
.tqmXq:hover:not(:disabled){background:#ffad00;}/*!sc*/
.tqmXq:hover:not(:disabled) > .icon-wrapper > svg{-webkit-transform:translateX(max(-5px,-0.08333333333333333rem)) rotate(270deg);-ms-transform:translateX(max(-5px,-0.08333333333333333rem)) rotate(270deg);transform:translateX(max(-5px,-0.08333333333333333rem)) rotate(270deg);}/*!sc*/
.iNInRn{-webkit-text-decoration:none;text-decoration:none;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:-webkit-fit-content;width:-moz-fit-content;width:fit-content;color:#000000;white-space:nowrap;height:max(35px,1.4933333333333334rem);padding:0 max(15px,0.25rem);border-radius:4px;background:transparent;border:1px solid #00000033;-webkit-transition:border-color 0.25s cubic-bezier(0.6,0,0.2,1);transition:border-color 0.25s cubic-bezier(0.6,0,0.2,1);font-size:max(12px,0.5973333333333334rem);line-height:max(12px,0.5973333333333334rem);font-weight:400;}/*!sc*/
.iNInRn:focus{outline:1px solid #ffad00;outline-offset:4px;}/*!sc*/
.iNInRn:focus:not(:focus-visible){outline:0;}/*!sc*/
.iNInRn > .icon-wrapper > svg{-webkit-flex:none;-ms-flex:none;flex:none;}/*!sc*/
@media (min-width:48em){.iNInRn{font-size:max(12px,0.2734375rem);line-height:max(12px,0.2734375rem);}}/*!sc*/
@media (min-width:64.0625em){.iNInRn{font-size:max(12px,0.23333333333333334rem);line-height:max(12px,0.23333333333333334rem);}}/*!sc*/
@media (min-width:48em){.iNInRn{height:max(35px,0.5833333333333334rem);}}/*!sc*/
.iNInRn:hover:not(:disabled){border-color:#000000;}/*!sc*/
data-styled.g19[id="sc-886f2911-1"]{content:"tqmXq,iNInRn,"}/*!sc*/
.bIjvtE{display:block;}/*!sc*/
data-styled.g20[id="sc-231c837a-0"]{content:"bIjvtE,"}/*!sc*/
.leoAPl{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;overflow:hidden;}/*!sc*/
data-styled.g21[id="sc-231c837a-1"]{content:"leoAPl,"}/*!sc*/
.bUwALi{white-space:break-spaces;display:inline-block;}/*!sc*/
data-styled.g22[id="sc-231c837a-2"]{content:"bUwALi,"}/*!sc*/
.cTwEJZ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;width:max(50px,0.8333333333333334rem);height:max(50px,0.8333333333333334rem);border:1px solid #00000033;border-radius:50%;cursor:pointer;-webkit-transition:border 0.15s cubic-bezier(0.6,0,0.2,1);transition:border 0.15s cubic-bezier(0.6,0,0.2,1);}/*!sc*/
.cTwEJZ:focus{outline:1px solid #ffad00;outline-offset:4px;}/*!sc*/
.cTwEJZ:focus:not(:focus-visible){outline:0;}/*!sc*/
.cTwEJZ > .icon-wrapper > svg > path{fill:#000000;}/*!sc*/
.cTwEJZ:hover{border-color:#000000;}/*!sc*/
.hFMTuV{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;width:max(60px,1rem);height:max(60px,1rem);border:1px solid #ffffff33;border-radius:50%;cursor:pointer;-webkit-transition:border 0.15s cubic-bezier(0.6,0,0.2,1);transition:border 0.15s cubic-bezier(0.6,0,0.2,1);}/*!sc*/
.hFMTuV:focus{outline:1px solid #ffad00;outline-offset:4px;}/*!sc*/
.hFMTuV:focus:not(:focus-visible){outline:0;}/*!sc*/
.hFMTuV > .icon-wrapper > svg > path{fill:#ffffff;}/*!sc*/
.hFMTuV:hover{border-color:#ffffff;}/*!sc*/
data-styled.g30[id="sc-b87c5082-0"]{content:"cTwEJZ,hFMTuV,"}/*!sc*/
.bcksfN{margin-bottom:0;}/*!sc*/
data-styled.g67[id="sc-2f258a60-0"]{content:"bcksfN,"}/*!sc*/
.ikUERX{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;background:#11100e;color:#ffffff;padding:0 1rem;position:relative;-webkit-transition:opacity 0.4s cubic-bezier(0.6,0,0.2,1);transition:opacity 0.4s cubic-bezier(0.6,0,0.2,1);}/*!sc*/
@media (min-width:64.0625em) and (pointer:fine) and (max-aspect-ratio:4/2){}/*!sc*/
data-styled.g69[id="sc-bc2a2328-0"]{content:"ikUERX,"}/*!sc*/
.fLIUiz{padding:max(40px,0.6666666666666666rem) 0;}/*!sc*/
@media (min-width:64.0625em){.fLIUiz{display:grid;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;grid-template-columns:1fr 1fr;padding:max(70px,1.1666666666666667rem) 0;}}/*!sc*/
data-styled.g70[id="sc-bc2a2328-1"]{content:"fLIUiz,"}/*!sc*/
.kuSqiN{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
@media (min-width:64.0625em){.kuSqiN{-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}}/*!sc*/
data-styled.g71[id="sc-bc2a2328-2"]{content:"kuSqiN,"}/*!sc*/
.kOsgKR{width:-webkit-fit-content;width:-moz-fit-content;width:fit-content;}/*!sc*/
.kOsgKR:focus{outline:1px solid #ffad00;outline-offset:4px;}/*!sc*/
.kOsgKR:focus:not(:focus-visible){outline:0;}/*!sc*/
@media (min-width:64.0625em){.kOsgKR{margin-bottom:max(40px,0.6666666666666666rem);}}/*!sc*/
data-styled.g72[id="sc-bc2a2328-3"]{content:"kOsgKR,"}/*!sc*/
.hpdLBx{display:grid;grid-template-columns:repeat(2,1fr);grid-auto-rows:1fr;grid-column-gap:2rem;grid-row-gap:max(25px,0.4166666666666667rem);margin-top:max(40px,0.6666666666666666rem);width:-webkit-fit-content;width:-moz-fit-content;width:fit-content;}/*!sc*/
.hpdLBx > a{-webkit-transition:opacity 0.25s cubic-bezier(0.6,0,0.2,1), color 0.25s cubic-bezier(0.2,0.85,0.45,1);transition:opacity 0.25s cubic-bezier(0.6,0,0.2,1), color 0.25s cubic-bezier(0.2,0.85,0.45,1);}/*!sc*/
.hpdLBx > a:hover{color:#ffad00;}/*!sc*/
.hpdLBx > span{opacity:0.5;-webkit-transition:opacity 0.25s cubic-bezier(0.6,0,0.2,1);transition:opacity 0.25s cubic-bezier(0.6,0,0.2,1);}/*!sc*/
@media (min-width:64.0625em){.hpdLBx{grid-template-columns:repeat(3,2rem);height:-webkit-fit-content;height:-moz-fit-content;height:fit-content;width:100%;margin-top:0;}}/*!sc*/
data-styled.g73[id="sc-bc2a2328-4"]{content:"hpdLBx,"}/*!sc*/
.ecIfRF{display:block;width:-webkit-fit-content;width:-moz-fit-content;width:fit-content;height:-webkit-fit-content;height:-moz-fit-content;height:fit-content;font-size:max(14px,0.7253333333333334rem);line-height:max(14px,0.6826666666666666rem);color:inherit;-webkit-text-decoration:none;text-decoration:none;grid-column:1;grid-row:1;}/*!sc*/
@media (min-width:48em){.ecIfRF{font-size:max(14px,0.33203125rem);line-height:max(14px,0.3125rem);}}/*!sc*/
@media (min-width:64.0625em){.ecIfRF{font-size:max(14px,0.2833333333333333rem);line-height:max(14px,0.26666666666666666rem);}}/*!sc*/
.ecIfRF:focus{outline:1px solid #ffad00;outline-offset:4px;}/*!sc*/
.ecIfRF:focus:not(:focus-visible){outline:0;}/*!sc*/
@media (min-width:64.0625em){.ecIfRF{grid-area:1 / 1;}}/*!sc*/
.gQMvHh{display:block;width:-webkit-fit-content;width:-moz-fit-content;width:fit-content;height:-webkit-fit-content;height:-moz-fit-content;height:fit-content;font-size:max(14px,0.7253333333333334rem);line-height:max(14px,0.6826666666666666rem);color:inherit;-webkit-text-decoration:none;text-decoration:none;grid-column:1;grid-row:2;}/*!sc*/
@media (min-width:48em){.gQMvHh{font-size:max(14px,0.33203125rem);line-height:max(14px,0.3125rem);}}/*!sc*/
@media (min-width:64.0625em){.gQMvHh{font-size:max(14px,0.2833333333333333rem);line-height:max(14px,0.26666666666666666rem);}}/*!sc*/
.gQMvHh:focus{outline:1px solid #ffad00;outline-offset:4px;}/*!sc*/
.gQMvHh:focus:not(:focus-visible){outline:0;}/*!sc*/
@media (min-width:64.0625em){.gQMvHh{grid-area:2 / 1;}}/*!sc*/
.wsigZ{display:block;width:-webkit-fit-content;width:-moz-fit-content;width:fit-content;height:-webkit-fit-content;height:-moz-fit-content;height:fit-content;font-size:max(14px,0.7253333333333334rem);line-height:max(14px,0.6826666666666666rem);color:inherit;-webkit-text-decoration:none;text-decoration:none;grid-column:1;grid-row:3;}/*!sc*/
@media (min-width:48em){.wsigZ{font-size:max(14px,0.33203125rem);line-height:max(14px,0.3125rem);}}/*!sc*/
@media (min-width:64.0625em){.wsigZ{font-size:max(14px,0.2833333333333333rem);line-height:max(14px,0.26666666666666666rem);}}/*!sc*/
.wsigZ:focus{outline:1px solid #ffad00;outline-offset:4px;}/*!sc*/
.wsigZ:focus:not(:focus-visible){outline:0;}/*!sc*/
@media (min-width:64.0625em){.wsigZ{grid-area:3 / 1;}}/*!sc*/
.cGRCnN{display:block;width:-webkit-fit-content;width:-moz-fit-content;width:fit-content;height:-webkit-fit-content;height:-moz-fit-content;height:fit-content;font-size:max(14px,0.7253333333333334rem);line-height:max(14px,0.6826666666666666rem);color:inherit;-webkit-text-decoration:none;text-decoration:none;grid-column:1;grid-row:4;}/*!sc*/
@media (min-width:48em){.cGRCnN{font-size:max(14px,0.33203125rem);line-height:max(14px,0.3125rem);}}/*!sc*/
@media (min-width:64.0625em){.cGRCnN{font-size:max(14px,0.2833333333333333rem);line-height:max(14px,0.26666666666666666rem);}}/*!sc*/
.cGRCnN:focus{outline:1px solid #ffad00;outline-offset:4px;}/*!sc*/
.cGRCnN:focus:not(:focus-visible){outline:0;}/*!sc*/
@media (min-width:64.0625em){.cGRCnN{grid-area:4 / 1;}}/*!sc*/
.hBLclq{display:block;width:-webkit-fit-content;width:-moz-fit-content;width:fit-content;height:-webkit-fit-content;height:-moz-fit-content;height:fit-content;font-size:max(14px,0.7253333333333334rem);line-height:max(14px,0.6826666666666666rem);color:inherit;-webkit-text-decoration:none;text-decoration:none;grid-column:1;grid-row:5;}/*!sc*/
@media (min-width:48em){.hBLclq{font-size:max(14px,0.33203125rem);line-height:max(14px,0.3125rem);}}/*!sc*/
@media (min-width:64.0625em){.hBLclq{font-size:max(14px,0.2833333333333333rem);line-height:max(14px,0.26666666666666666rem);}}/*!sc*/
.hBLclq:focus{outline:1px solid #ffad00;outline-offset:4px;}/*!sc*/
.hBLclq:focus:not(:focus-visible){outline:0;}/*!sc*/
@media (min-width:64.0625em){.hBLclq{grid-area:1 / 2;}}/*!sc*/
.kpyAym{display:block;width:-webkit-fit-content;width:-moz-fit-content;width:fit-content;height:-webkit-fit-content;height:-moz-fit-content;height:fit-content;font-size:max(14px,0.7253333333333334rem);line-height:max(14px,0.6826666666666666rem);color:inherit;-webkit-text-decoration:none;text-decoration:none;grid-column:1;grid-row:6;}/*!sc*/
@media (min-width:48em){.kpyAym{font-size:max(14px,0.33203125rem);line-height:max(14px,0.3125rem);}}/*!sc*/
@media (min-width:64.0625em){.kpyAym{font-size:max(14px,0.2833333333333333rem);line-height:max(14px,0.26666666666666666rem);}}/*!sc*/
.kpyAym:focus{outline:1px solid #ffad00;outline-offset:4px;}/*!sc*/
.kpyAym:focus:not(:focus-visible){outline:0;}/*!sc*/
@media (min-width:64.0625em){.kpyAym{grid-area:2 / 2;}}/*!sc*/
.dUNvvy{display:block;width:-webkit-fit-content;width:-moz-fit-content;width:fit-content;height:-webkit-fit-content;height:-moz-fit-content;height:fit-content;font-size:max(14px,0.7253333333333334rem);line-height:max(14px,0.6826666666666666rem);color:inherit;-webkit-text-decoration:none;text-decoration:none;grid-column:1;grid-row:7;}/*!sc*/
@media (min-width:48em){.dUNvvy{font-size:max(14px,0.33203125rem);line-height:max(14px,0.3125rem);}}/*!sc*/
@media (min-width:64.0625em){.dUNvvy{font-size:max(14px,0.2833333333333333rem);line-height:max(14px,0.26666666666666666rem);}}/*!sc*/
.dUNvvy:focus{outline:1px solid #ffad00;outline-offset:4px;}/*!sc*/
.dUNvvy:focus:not(:focus-visible){outline:0;}/*!sc*/
@media (min-width:64.0625em){.dUNvvy{grid-area:3 / 2;}}/*!sc*/
.cEMzPg{display:block;width:-webkit-fit-content;width:-moz-fit-content;width:fit-content;height:-webkit-fit-content;height:-moz-fit-content;height:fit-content;font-size:max(14px,0.7253333333333334rem);line-height:max(14px,0.6826666666666666rem);color:inherit;-webkit-text-decoration:none;text-decoration:none;grid-column:2;grid-row:1;}/*!sc*/
@media (min-width:48em){.cEMzPg{font-size:max(14px,0.33203125rem);line-height:max(14px,0.3125rem);}}/*!sc*/
@media (min-width:64.0625em){.cEMzPg{font-size:max(14px,0.2833333333333333rem);line-height:max(14px,0.26666666666666666rem);}}/*!sc*/
.cEMzPg:focus{outline:1px solid #ffad00;outline-offset:4px;}/*!sc*/
.cEMzPg:focus:not(:focus-visible){outline:0;}/*!sc*/
@media (min-width:64.0625em){.cEMzPg{grid-area:1 / 3;}}/*!sc*/
.eXGrwc{display:block;width:-webkit-fit-content;width:-moz-fit-content;width:fit-content;height:-webkit-fit-content;height:-moz-fit-content;height:fit-content;font-size:max(14px,0.7253333333333334rem);line-height:max(14px,0.6826666666666666rem);color:inherit;-webkit-text-decoration:none;text-decoration:none;grid-column:2;grid-row:2;}/*!sc*/
@media (min-width:48em){.eXGrwc{font-size:max(14px,0.33203125rem);line-height:max(14px,0.3125rem);}}/*!sc*/
@media (min-width:64.0625em){.eXGrwc{font-size:max(14px,0.2833333333333333rem);line-height:max(14px,0.26666666666666666rem);}}/*!sc*/
.eXGrwc:focus{outline:1px solid #ffad00;outline-offset:4px;}/*!sc*/
.eXGrwc:focus:not(:focus-visible){outline:0;}/*!sc*/
@media (min-width:64.0625em){.eXGrwc{grid-area:2 / 3;}}/*!sc*/
.glKgEY{display:block;width:-webkit-fit-content;width:-moz-fit-content;width:fit-content;height:-webkit-fit-content;height:-moz-fit-content;height:fit-content;font-size:max(14px,0.7253333333333334rem);line-height:max(14px,0.6826666666666666rem);color:inherit;-webkit-text-decoration:none;text-decoration:none;grid-column:2;grid-row:3;}/*!sc*/
@media (min-width:48em){.glKgEY{font-size:max(14px,0.33203125rem);line-height:max(14px,0.3125rem);}}/*!sc*/
@media (min-width:64.0625em){.glKgEY{font-size:max(14px,0.2833333333333333rem);line-height:max(14px,0.26666666666666666rem);}}/*!sc*/
.glKgEY:focus{outline:1px solid #ffad00;outline-offset:4px;}/*!sc*/
.glKgEY:focus:not(:focus-visible){outline:0;}/*!sc*/
@media (min-width:64.0625em){.glKgEY{grid-area:3 / 3;}}/*!sc*/
.ePTDbg{display:block;width:-webkit-fit-content;width:-moz-fit-content;width:fit-content;height:-webkit-fit-content;height:-moz-fit-content;height:fit-content;font-size:max(14px,0.7253333333333334rem);line-height:max(14px,0.6826666666666666rem);color:inherit;-webkit-text-decoration:none;text-decoration:none;grid-column:2;grid-row:4;}/*!sc*/
@media (min-width:48em){.ePTDbg{font-size:max(14px,0.33203125rem);line-height:max(14px,0.3125rem);}}/*!sc*/
@media (min-width:64.0625em){.ePTDbg{font-size:max(14px,0.2833333333333333rem);line-height:max(14px,0.26666666666666666rem);}}/*!sc*/
.ePTDbg:focus{outline:1px solid #ffad00;outline-offset:4px;}/*!sc*/
.ePTDbg:focus:not(:focus-visible){outline:0;}/*!sc*/
@media (min-width:64.0625em){.ePTDbg{grid-area:4 / 3;}}/*!sc*/
data-styled.g74[id="sc-bc2a2328-5"]{content:"ecIfRF,gQMvHh,wsigZ,cGRCnN,hBLclq,kpyAym,dUNvvy,cEMzPg,eXGrwc,glKgEY,ePTDbg,"}/*!sc*/
.lkNUFO{width:100%;text-align:center;border-top:1px solid #ffffff1a;padding:max(15px,0.25rem) 0;color:#ffffff80;margin:0;font-weight:400;}/*!sc*/
data-styled.g75[id="sc-bc2a2328-6"]{content:"lkNUFO,"}/*!sc*/
.cBvKUu{position:relative;padding:calc(max(40px,0.6666666666666666rem) + max(25px,0.4166666666666667rem) + max(70px,1.1666666666666667rem)) 1rem max(70px,1.1666666666666667rem);background:#ede8e6;z-index:1;}/*!sc*/
.cBvKUu > *:first-child{margin-top:0;}/*!sc*/
@media (min-width:48em){.cBvKUu{padding-top:calc( max(50px,0.8333333333333334rem) + max(40px,0.6666666666666666rem) + max(70px,1.1666666666666667rem) );padding-bottom:max(70px,1.1666666666666667rem);}}/*!sc*/
@media (min-width:64.0625em){.cBvKUu{padding-bottom:max(110px,1.8333333333333333rem);}}/*!sc*/
data-styled.g77[id="sc-4148e60f-0"]{content:"cBvKUu,"}/*!sc*/
@media (min-width:48em){.focBNJ{padding:0 4rem;}}/*!sc*/
@media (min-width:64.0625em){.focBNJ{padding:0 5rem;}}/*!sc*/
data-styled.g81[id="sc-7ac6e6d8-0"]{content:"focBNJ,"}/*!sc*/
.dIZbPw{font-size:2.0906666666666665rem;line-height:1.8346666666666667rem;-webkit-letter-spacing:-0.034133333333333335rem;-moz-letter-spacing:-0.034133333333333335rem;-ms-letter-spacing:-0.034133333333333335rem;letter-spacing:-0.034133333333333335rem;margin:max(40px,0.6666666666666666rem) 0 0;}/*!sc*/
@media (min-width:48em){.dIZbPw{font-size:1.62109375rem;line-height:1.40625rem;-webkit-letter-spacing:-0.01953125rem;-moz-letter-spacing:-0.01953125rem;-ms-letter-spacing:-0.01953125rem;letter-spacing:-0.01953125rem;}}/*!sc*/
@media (min-width:64.0625em){.dIZbPw{font-size:1.9333333333333333rem;line-height:1.6666666666666667rem;-webkit-letter-spacing:-0.03333333333333333rem;-moz-letter-spacing:-0.03333333333333333rem;-ms-letter-spacing:-0.03333333333333333rem;letter-spacing:-0.03333333333333333rem;}}/*!sc*/
@media (min-width:48em){.dIZbPw{margin-top:max(70px,1.1666666666666667rem);}}/*!sc*/
@media (min-width:64.0625em){.dIZbPw{margin-top:max(110px,1.8333333333333333rem);}}/*!sc*/
.dIZbPw u{background:linear-gradient(#ffad00,#ffad00);background-repeat:no-repeat;background-position:0 90%,100% 100%;background-size:100% 0.128rem,0 0.128rem;}/*!sc*/
@media (min-width:48em){.dIZbPw u{background-size:100% 0.1171875rem,0 0.1171875rem;}}/*!sc*/
@media (min-width:64.0625em){.dIZbPw u{background-size:100% 0.13333333333333333rem,0 0.13333333333333333rem;}}/*!sc*/
.dSayTV{font-size:1.28rem;line-height:1.2373333333333334rem;-webkit-letter-spacing:-0.025599999999999998rem;-moz-letter-spacing:-0.025599999999999998rem;-ms-letter-spacing:-0.025599999999999998rem;letter-spacing:-0.025599999999999998rem;margin:max(25px,0.4166666666666667rem) 0 0;}/*!sc*/
@media (min-width:48em){.dSayTV{font-size:0.78125rem;line-height:0.7421875rem;-webkit-letter-spacing:-0.009765625rem;-moz-letter-spacing:-0.009765625rem;-ms-letter-spacing:-0.009765625rem;letter-spacing:-0.009765625rem;}}/*!sc*/
@media (min-width:64.0625em){.dSayTV{font-size:0.8333333333333334rem;line-height:0.8rem;-webkit-letter-spacing:-0.016666666666666666rem;-moz-letter-spacing:-0.016666666666666666rem;-ms-letter-spacing:-0.016666666666666666rem;letter-spacing:-0.016666666666666666rem;}}/*!sc*/
@media (min-width:48em){.dSayTV{margin-top:max(25px,0.4166666666666667rem);}}/*!sc*/
@media (min-width:64.0625em){.dSayTV{margin-top:max(40px,0.6666666666666666rem);}}/*!sc*/
.dSayTV u{display:inline;background:linear-gradient(#ffad00,#ffad00);background-repeat:no-repeat;background-position:0 72%,100% 100%;background-size:100% 0.128rem,0 0.128rem;}/*!sc*/
@media (min-width:48em){.dSayTV u{background-size:100% 0.05859375rem,0 0.05859375rem;}}/*!sc*/
@media (min-width:64.0625em){.dSayTV u{background-size:100% 0.05rem,0 0.05rem;}}/*!sc*/
data-styled.g82[id="sc-d2305c5b-0"]{content:"dIZbPw,dSayTV,"}/*!sc*/
.lLzzc{-webkit-text-decoration:none;text-decoration:none;white-space:break-spaces;display:inline-block;}/*!sc*/
data-styled.g83[id="sc-d2305c5b-1"]{content:"lLzzc,"}/*!sc*/
.diiQNG > *:last-child{margin-bottom:0;}/*!sc*/
data-styled.g102[id="sc-2e5c88b1-0"]{content:"diiQNG,"}/*!sc*/
.evXWfb{background:linear-gradient(#000000,#000000);background-size:100% 1px,0 1px;background-position:100% 100%,0 100%;background-repeat:no-repeat;color:inherit;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
.evXWfb:hover{background-size:0 1px,100% 1px;background-position:0 100%,100% 100%;-webkit-transition:background-position 0s 0.4s, background-size 0.4s cubic-bezier(0.7,0.005,0.3,1);transition:background-position 0s 0.4s, background-size 0.4s cubic-bezier(0.7,0.005,0.3,1);-webkit-animation:irGDNB 0.4s cubic-bezier(0.2,0.85,0.45,1) 0.4s forwards;animation:irGDNB 0.4s cubic-bezier(0.2,0.85,0.45,1) 0.4s forwards;}/*!sc*/
.evXWfb:focus{outline:1px solid #ffad00;outline-offset:4px;}/*!sc*/
.evXWfb:focus:not(:focus-visible){outline:0;}/*!sc*/
data-styled.g103[id="sc-2e5c88b1-1"]{content:"evXWfb,"}/*!sc*/
.cLSWOT{margin-bottom:max(15px,0.25rem);}/*!sc*/
data-styled.g104[id="sc-2e5c88b1-2"]{content:"cLSWOT,"}/*!sc*/
.bDBNNm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/
data-styled.g166[id="sc-13cee2ed-0"]{content:"bDBNNm,"}/*!sc*/
.kCikXL{-webkit-flex:none;-ms-flex:none;flex:none;}/*!sc*/
data-styled.g167[id="sc-13cee2ed-1"]{content:"kCikXL,"}/*!sc*/
.jinLpX{font-size:max(12px,0.5973333333333334rem);line-height:max(12px,0.5973333333333334rem);font-weight:400;margin-left:max(10px,0.16666666666666666rem);}/*!sc*/
@media (min-width:48em){.jinLpX{font-size:max(12px,0.2734375rem);line-height:max(12px,0.2734375rem);}}/*!sc*/
@media (min-width:64.0625em){.jinLpX{font-size:max(12px,0.23333333333333334rem);line-height:max(12px,0.23333333333333334rem);}}/*!sc*/
data-styled.g168[id="sc-13cee2ed-2"]{content:"jinLpX,"}/*!sc*/
.xdiVk{color:inherit;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
.xdiVk:is(a){display:inline;background:linear-gradient(#000000,#000000);background-size:0 1px,100% 1px;background-position:0 88%,88% 88%;background-repeat:no-repeat;-webkit-transition:background-size 0.4s cubic-bezier(0.6,0,0.2,1);transition:background-size 0.4s cubic-bezier(0.6,0,0.2,1);}/*!sc*/
.xdiVk:is(a):hover{background-size:100% 1px,0 1px;}/*!sc*/
.xdiVk:is(a):focus{outline:1px solid #ffad00;outline-offset:4px;}/*!sc*/
.xdiVk:is(a):focus:not(:focus-visible){outline:0;}/*!sc*/
data-styled.g169[id="sc-13cee2ed-3"]{content:"xdiVk,"}/*!sc*/
.eRDOMB{height:100%;}/*!sc*/
data-styled.g212[id="sc-e532795e-0"]{content:"eRDOMB,"}/*!sc*/
.gyCYJ{margin-top:max(40px,0.6666666666666666rem);}/*!sc*/
@media (min-width:48em){.gyCYJ{margin-top:max(70px,1.1666666666666667rem);}}/*!sc*/
data-styled.g214[id="sc-2cc3f61e-0"]{content:"gyCYJ,"}/*!sc*/
.ehDhYc{margin:max(15px,0.25rem) 0 0;font-weight:400;}/*!sc*/
@media (min-width:48em){.ehDhYc{max-width:8rem;}}/*!sc*/
data-styled.g215[id="sc-2cc3f61e-1"]{content:"ehDhYc,"}/*!sc*/
.fkCieZ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;}/*!sc*/
data-styled.g270[id="sc-34174fa0-0"]{content:"fkCieZ,"}/*!sc*/
.ksIrsv{margin:0 0 max(10px,0.16666666666666666rem);border-bottom:1px solid #000000;}/*!sc*/
data-styled.g271[id="sc-34174fa0-1"]{content:"ksIrsv,"}/*!sc*/
.iWhknh{margin-top:max(10px,0.16666666666666666rem);}/*!sc*/
data-styled.g273[id="sc-34174fa0-3"]{content:"iWhknh,"}/*!sc*/
.jbhrap{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;}/*!sc*/
data-styled.g274[id="sc-d11d9e57-0"]{content:"jbhrap,"}/*!sc*/
.jzZCjv{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;gap:max(15px,0.25rem);margin-top:max(10px,0.16666666666666666rem);}/*!sc*/
data-styled.g275[id="sc-d11d9e57-1"]{content:"jzZCjv,"}/*!sc*/
.cjHfXU{margin:0 0 max(10px,0.16666666666666666rem);border-bottom:1px solid #000000;}/*!sc*/
data-styled.g276[id="sc-d11d9e57-2"]{content:"cjHfXU,"}/*!sc*/
.dXdtVx{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:relative;}/*!sc*/
@media (min-width:48em){.dXdtVx{padding-left:4rem;}}/*!sc*/
@media (min-width:64.0625em){.dXdtVx{padding-left:5rem;}}/*!sc*/
data-styled.g277[id="sc-b571a629-0"]{content:"dXdtVx,"}/*!sc*/
.kJNwwk{margin-bottom:max(25px,0.4166666666666667rem);}/*!sc*/
@media (min-width:48em){.kJNwwk{position:absolute;left:0;}}/*!sc*/
data-styled.g278[id="sc-b571a629-1"]{content:"kJNwwk,"}/*!sc*/
.fmgXze{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;margin-bottom:max(40px,0.6666666666666666rem);}/*!sc*/
@media (min-width:48em){.fmgXze{-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;margin-bottom:max(40px,0.6666666666666666rem);}}/*!sc*/
@media (min-width:64.0625em){.fmgXze{margin-bottom:max(70px,1.1666666666666667rem);}}/*!sc*/
data-styled.g279[id="sc-b571a629-2"]{content:"fmgXze,"}/*!sc*/
.bqBRmc{margin-bottom:max(25px,0.4166666666666667rem);}/*!sc*/
@media (min-width:48em){.bqBRmc{margin-bottom:0;}}/*!sc*/
data-styled.g280[id="sc-b571a629-3"]{content:"bqBRmc,"}/*!sc*/
.fYmfzH{margin-bottom:0 !important;}/*!sc*/
data-styled.g281[id="sc-b571a629-4"]{content:"fYmfzH,"}/*!sc*/
.izzLFj{margin:0 0 max(25px,0.4166666666666667rem);}/*!sc*/
@media (min-width:48em){.izzLFj{margin:0 0 max(40px,0.6666666666666666rem);}}/*!sc*/
data-styled.g282[id="sc-b571a629-5"]{content:"izzLFj,"}/*!sc*/
.goOQs{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}/*!sc*/
.goOQs > *:first-child > *:first-child{margin-top:0;}/*!sc*/
.goOQs > *{margin-top:max(40px,0.6666666666666666rem);}/*!sc*/
@media (min-width:64.0625em){.goOQs > *{margin-top:max(70px,1.1666666666666667rem);}}/*!sc*/
@media (min-width:48em){.goOQs > .sc-e532795e-1,.goOQs > .sc-5e8a46bf-0{min-width:15rem;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;}}/*!sc*/
@media (min-width:64.0625em){.goOQs > .sc-e532795e-1,.goOQs > .sc-5e8a46bf-0{min-width:18rem;}}/*!sc*/
data-styled.g346[id="sc-fdb2fb33-0"]{content:"goOQs,"}/*!sc*/
.iAArmB{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:max(25px,0.4166666666666667rem);-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}/*!sc*/
@media (min-width:64.0625em){.iAArmB{-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;gap:1rem;}}/*!sc*/
data-styled.g347[id="sc-fdb2fb33-1"]{content:"iAArmB,"}/*!sc*/
.idSFyV{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:max(10px,0.16666666666666666rem);}/*!sc*/
data-styled.g354[id="sc-58720d67-0"]{content:"idSFyV,"}/*!sc*/
.gCJaqj{position:relative;}/*!sc*/
.gCJaqj:after{content:'';position:absolute;height:calc(100% + 2px);width:calc(100% + 2px);background:#ffad00;border-radius:100%;-webkit-transform:scale(0);-ms-transform:scale(0);transform:scale(0);-webkit-transition:-webkit-transform 0.4s cubic-bezier(0.6,0,0.2,1);-webkit-transition:transform 0.4s cubic-bezier(0.6,0,0.2,1);transition:transform 0.4s cubic-bezier(0.6,0,0.2,1);}/*!sc*/
data-styled.g355[id="sc-58720d67-1"]{content:"gCJaqj,"}/*!sc*/
@-webkit-keyframes hUniol{from{opacity:0;}to{opacity:1;}}/*!sc*/
@keyframes hUniol{from{opacity:0;}to{opacity:1;}}/*!sc*/
data-styled.g376[id="sc-keyframes-hUniol"]{content:"hUniol,"}/*!sc*/
@-webkit-keyframes hbjThv{to{opacity:1;}}/*!sc*/
@keyframes hbjThv{to{opacity:1;}}/*!sc*/
data-styled.g377[id="sc-keyframes-hbjThv"]{content:"hbjThv,"}/*!sc*/
@-webkit-keyframes irGDNB{to{background-size:100% 1px,0 1px;}}/*!sc*/
@keyframes irGDNB{to{background-size:100% 1px,0 1px;}}/*!sc*/
data-styled.g378[id="sc-keyframes-irGDNB"]{content:"irGDNB,"}/*!sc*/
</style></head><body><div id="__next" data-reactroot=""><main data-scroll-container="true" class="sc-f641962e-0 bCAHtX"><div data-scroll-section="true" style="opacity:1"><div class="sc-4148e60f-0 cBvKUu"><header class="sc-b571a629-0 dXdtVx"><a class="sc-886f2911-1 tqmXq sc-b571a629-1 kJNwwk" href="../thinking.html"><div class="sc-faf29a58-0 hbJg icon-wrapper"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 13 16" width="100%" height="100%" class="sc-cbc7a3bd-0 gLPuKv"><path fill="#000" fill-rule="evenodd" d="M2.258 7.914L.844 6.5l4.242-4.243L6.501.843l1.414 1.414L12.158 6.5l-1.415 1.414-3.242-3.242V15.5h-2V4.671L2.258 7.915z" clip-rule="evenodd"></path></svg></div></a><h2 class="sc-d2305c5b-0 dIZbPw sc-b571a629-5 izzLFj"><span class="sc-231c837a-0 bIjvtE" aria-label="Efficiently Initializing Reinforcement Learning With Prior Policies"><span aria-hidden="true" class="sc-231c837a-1 leoAPl"><span class="sc-231c837a-2 bUwALi" style="transform:translateY(100%) translateZ(0)">Efficiently </span></span><span aria-hidden="true" class="sc-231c837a-1 leoAPl"><span class="sc-231c837a-2 bUwALi" style="transform:translateY(100%) translateZ(0)">Initializing </span></span><span aria-hidden="true" class="sc-231c837a-1 leoAPl"><span class="sc-231c837a-2 bUwALi" style="transform:translateY(100%) translateZ(0)">Reinforcement </span></span><span aria-hidden="true" class="sc-231c837a-1 leoAPl"><span class="sc-231c837a-2 bUwALi" style="transform:translateY(100%) translateZ(0)">Learning </span></span><span aria-hidden="true" class="sc-231c837a-1 leoAPl"><span class="sc-231c837a-2 bUwALi" style="transform:translateY(100%) translateZ(0)">With </span></span><span aria-hidden="true" class="sc-231c837a-1 leoAPl"><span class="sc-231c837a-2 bUwALi" style="transform:translateY(100%) translateZ(0)">Prior </span></span><span aria-hidden="true" class="sc-231c837a-1 leoAPl"><span class="sc-231c837a-2 bUwALi" style="transform:translateY(100%) translateZ(0)">Policies</span></span></span></h2><div class="sc-b571a629-2 fmgXze"><div class="sc-b571a629-3 bqBRmc"><p class="sc-d57e93a-0 jZunqb sc-2f258a60-0 bcksfN">by  Ikechukwu Uchendu, Ted Xiao</p><p class="sc-d57e93a-0 jZunqb sc-b571a629-4 fYmfzH">Apr 06, 2022</p></div><div class="sc-58720d67-0 idSFyV"><a class="sc-b87c5082-0 cTwEJZ" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Feverydayrobots.com%2Fthinking%2Fefficiently-initializing-reinforcement-learning-with-prior-policies" target="_blank" rel="noopener noreferrer" aria-label="Facebook" tabindex="0"><div class="sc-faf29a58-0 jXynWI icon-wrapper"><svg viewBox="0 0 12 22" fill="none" xmlns="http://www.w3.org/2000/svg" width="100%" height="100%"><path d="M10.354 12.063l.519-3.415H7.57V6.422c0-.965.446-1.856 1.93-1.856h1.521V1.635s-1.373-.26-2.671-.26c-2.71 0-4.49 1.67-4.49 4.639v2.634H.815v3.415H3.86v8.312H7.57v-8.313h2.784z" fill="#000"></path></svg></div></a><a class="sc-b87c5082-0 cTwEJZ" href="https://linkedin.com/shareArticle?url=https%3A%2F%2Feverydayrobots.com%2Fthinking%2Fefficiently-initializing-reinforcement-learning-with-prior-policies&amp;mini=true" target="_blank" rel="noopener noreferrer" aria-label="Linkedin" tabindex="0"><div class="sc-faf29a58-0 cBpQkk icon-wrapper"><svg viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg" width="100%" height="100%"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.278 0C.572 0 0 .572 0 1.278v15.444C0 17.428.572 18 1.278 18h15.444c.706 0 1.278-.572 1.278-1.278V1.278C18 .572 17.428 0 16.722 0H1.278zM4.04 5.59a1.562 1.562 0 100-3.123 1.562 1.562 0 000 3.123zm2.992 1.154H9.62v1.185s.702-1.404 2.613-1.404c1.704 0 3.116.84 3.116 3.399v5.397h-2.682v-4.743c0-1.51-.806-1.676-1.42-1.676-1.275 0-1.493 1.1-1.493 1.873v4.546H7.032V6.744zm-1.63 0H2.678v8.577h2.722V6.744z" fill="#000"></path></svg></div></a><a class="sc-b87c5082-0 cTwEJZ" href="https://twitter.com/share?url=https%3A%2F%2Feverydayrobots.com%2Fthinking%2Fefficiently-initializing-reinforcement-learning-with-prior-policies" target="_blank" rel="noopener noreferrer" aria-label="Twitter" tabindex="0"><div class="sc-faf29a58-0 jXynWI icon-wrapper"><svg viewBox="0 0 19 14" fill="none" xmlns="http://www.w3.org/2000/svg" width="100%" height="100%"><path d="M6.3 13.5c6.54 0 10.117-5.002 10.117-9.339 0-.14-.003-.284-.01-.425a6.941 6.941 0 001.774-1.7 7.474 7.474 0 01-2.041.516A3.361 3.361 0 0017.704.737a7.52 7.52 0 01-2.258.797 3.662 3.662 0 00-2.018-.991 3.82 3.82 0 00-2.254.345 3.41 3.41 0 00-1.563 1.54 3.055 3.055 0 00-.227 2.099 10.767 10.767 0 01-4.059-.995A9.995 9.995 0 012.055 1.1a3.068 3.068 0 00-.388 2.39c.205.814.737 1.526 1.49 1.99a3.79 3.79 0 01-1.612-.41v.041c0 .758.284 1.493.804 2.08s1.244.99 2.05 1.139a3.82 3.82 0 01-1.605.056c.227.652.67 1.223 1.264 1.632a3.76 3.76 0 002.056.65 7.52 7.52 0 01-4.417 1.406c-.284 0-.567-.017-.85-.048A10.71 10.71 0 006.302 13.5z" fill="#000"></path></svg></div></a><span class="sc-b87c5082-0 cTwEJZ sc-58720d67-1 gCJaqj" aria-label="Copy" tabindex="0"><div class="sc-faf29a58-0 jXynWI icon-wrapper"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 22 22" width="100%" height="100%"><path fill="#000" fill-rule="evenodd" d="M14.536 11l3.182-3.183a2.5 2.5 0 10-3.536-3.535L11 7.464 12.237 8.7l1.061-1.06 1.06 1.06-1.06 1.06L14.536 11zm-2.299-.178l1.238 1.238 1.06 1.06 1.061-1.06 3.182-3.182a4 4 0 00-5.657-5.657L9.94 6.403l-1.06 1.06 1.06 1.061 1.238 1.238-1.414 1.414-1.238-1.237-1.06-1.061-1.061 1.06-3.182 3.182a4 4 0 005.657 5.657l3.182-3.182 1.06-1.06-1.06-1.06-1.238-1.238 1.414-1.415zm-3.535 1.415l-1.06 1.06 1.06 1.06 1.06-1.06L11 14.535l-3.182 3.182a2.5 2.5 0 01-3.536-3.536L7.464 11l1.238 1.238z" clip-rule="evenodd"></path></svg></div></span></div></div></header><div class="sc-f59e9df7-2 eglMLr undefined media-wrapper"><picture class="sc-f59e9df7-0 gGvOxe"><source data-type="image/webp" data-srcset="/_next/static/images/4hO9HJ5AyTzOSwQlzIEnky-64-5a45ab96700b1ce02783be49348e3e98.webp 64w,/_next/static/images/4hO9HJ5AyTzOSwQlzIEnky-128-1c599f475f8c2b33ada05643c5e505d7.webp 128w,/_next/static/images/4hO9HJ5AyTzOSwQlzIEnky-256-495aea78274151cb006345111cde88f5.webp 256w,/_next/static/images/4hO9HJ5AyTzOSwQlzIEnky-512-105ce1f4f15d7ee6ee52426df128252e.webp 512w,/_next/static/images/4hO9HJ5AyTzOSwQlzIEnky-1024-bcff44feb4d510289679462deeaabb9f.webp 1024w,/_next/static/images/4hO9HJ5AyTzOSwQlzIEnky-1536-df22af34e1ca36af7bb7cc23cf457f91.webp 1536w,/_next/static/images/4hO9HJ5AyTzOSwQlzIEnky-2000-dfa2694d95b56f2ccdc31fc0124643c5.webp 2000w" data-scroll="true" data-scroll-speed="-1"/><img data-src="/_next/static/images/4hO9HJ5AyTzOSwQlzIEnky-64-f5eea4ef59ec8a7e0181e1b06f99de8a.jpg" data-srcset="/_next/static/images/4hO9HJ5AyTzOSwQlzIEnky-64-f5eea4ef59ec8a7e0181e1b06f99de8a.jpg 64w,/_next/static/images/4hO9HJ5AyTzOSwQlzIEnky-128-1486167dcf99a70abcac09c6c39da3ee.jpg 128w,/_next/static/images/4hO9HJ5AyTzOSwQlzIEnky-256-1ca98d8584b3bfa9e35b76ac8fc6bbb8.jpg 256w,/_next/static/images/4hO9HJ5AyTzOSwQlzIEnky-512-f0af4e927cbce91907e074fbcd4fe926.jpg 512w,/_next/static/images/4hO9HJ5AyTzOSwQlzIEnky-1024-8bfd694efe5ed2bf92ec4aad30f95107.jpg 1024w,/_next/static/images/4hO9HJ5AyTzOSwQlzIEnky-1536-fb367019ef6764b7c86ffa366220642e.jpg 1536w,/_next/static/images/4hO9HJ5AyTzOSwQlzIEnky-2000-11dddc2ae773fd77e1b91832587f3f09.jpg 2000w" alt="Robot sorting in real and sim " data-scroll="true" data-scroll-speed="-1"/></picture></div><div class="sc-7ac6e6d8-0 focBNJ"><div class="sc-fdb2fb33-0 goOQs"><div class="sc-2e5c88b1-0 diiQNG"><p class="sc-d57e93a-0 edIRpA"><i>This piece was first published on the </i><a class="sc-2e5c88b1-1 evXWfb" href="https://ai.googleblog.com/2022/04/efficiently-initializing-reinforcement.html" target="_blank" rel="noopener noreferrer"><i>Google AI Blog</i></a><i>.</i></p><p class="sc-d57e93a-0 edIRpA"><a class="sc-2e5c88b1-1 evXWfb" href="https://en.wikipedia.org/wiki/Reinforcement_learning" target="_blank" rel="noopener noreferrer">Reinforcement learning</a> (RL) can be used to train a policy to perform a task via trial and error, but a major challenge in RL is learning policies from scratch in environments with hard exploration challenges. For example, consider the setting depicted in the door-binary-v0 environment from the <a class="sc-2e5c88b1-1 evXWfb" href="https://github.com/aravindr93/hand_dapg/" target="_blank" rel="noopener noreferrer">adroit manipulation suite</a>, where an RL agent must control a hand in 3D space to open a door placed in front of it.</p></div><div class="sc-e532795e-1 bXjBJo sc-2cc3f61e-0 gyCYJ"><div class="sc-f59e9df7-2 YtoQn sc-e532795e-0 eRDOMB media-wrapper"><video autoplay="" loop="" muted="" playsinline="" aria-label=" An RL agent must control a hand in 3D space to open a door placed in front of it. The agent receives a reward signal only when the door is completely open. " preload="metadata" disablepictureinpicture="" class="sc-f59e9df7-1 iaNrAz"><source data-src="/_next/static/videos/78TKfKvQakZj6kXpSxIvvS-299e90fa4cd89389a03da477c1c66f3b.mp4" type="video/mp4"/></video></div><p class="sc-d57e93a-0 imkcGb sc-2cc3f61e-1 ehDhYc">
An RL agent must control a hand in 3D space to open a door placed in front of it. The agent receives a reward signal only when the door is completely open. 
</p></div><div class="sc-2e5c88b1-0 diiQNG"><p class="sc-d57e93a-0 edIRpA">Since the agent receives no intermediary rewards, it cannot measure how close it is to completing the task, and so must explore the space randomly until it eventually opens the door. Given how long the task takes and the precise control required, this is extremely unlikely.</p><p class="sc-d57e93a-0 edIRpA">For tasks like this, we can avoid exploring the state space randomly by using prior information. This prior information helps the agent understand which states of the environment are good, and should be further explored. We could use offline data (i.e., data collected by human demonstrators, scripted policies, or other RL agents) to train a policy, then use it to initialize a new RL policy. In the case where we use neural networks to represent the policies, this would involve copying the pre-trained policy’s neural network over to the new RL policy. This procedure makes the new RL policy behave like the pre-trained policy. However, naïvely initializing a new RL policy like this often works poorly, especially for<a class="sc-2e5c88b1-1 evXWfb" href="https://en.wikipedia.org/wiki/Value_function" target="_blank" rel="noopener noreferrer"><u> value-based RL</u></a> methods, as shown below.</p></div><div class="sc-e532795e-1 bXjBJo sc-2cc3f61e-0 gyCYJ"><div class="sc-f59e9df7-2 cyoGde sc-e532795e-0 eRDOMB media-wrapper"><picture class="sc-f59e9df7-0 gGvOxe"><source data-type="image/webp" data-srcset="/_next/static/images/5E6oGpSqVAcDPjYT7KjC4S-64-f9e148e8569ec5fa3a8d3aee3e99ce3c.webp 64w,/_next/static/images/5E6oGpSqVAcDPjYT7KjC4S-128-18f493e7fe50a1af9d586a8f07986082.webp 128w,/_next/static/images/5E6oGpSqVAcDPjYT7KjC4S-256-6e42940eb7dbc796d7e4e5ce7fbf013a.webp 256w,/_next/static/images/5E6oGpSqVAcDPjYT7KjC4S-512-fbed0c5dac138d9e39e78c365971adbf.webp 512w,/_next/static/images/5E6oGpSqVAcDPjYT7KjC4S-1024-d56135c2fd758f0ae001939c9d3e1f07.webp 1024w,/_next/static/images/5E6oGpSqVAcDPjYT7KjC4S-1074-e3a5b22f65dc1e9fae623b43f3f2446c.webp 1074w"/><img data-src="/_next/static/images/5E6oGpSqVAcDPjYT7KjC4S-64-f759a8a4de701ad7cd7f3c7e1c37fc31.png" data-srcset="/_next/static/images/5E6oGpSqVAcDPjYT7KjC4S-64-f759a8a4de701ad7cd7f3c7e1c37fc31.png 64w,/_next/static/images/5E6oGpSqVAcDPjYT7KjC4S-128-e9d1e24a2370ccf756cd171b0e60e5be.png 128w,/_next/static/images/5E6oGpSqVAcDPjYT7KjC4S-256-a418b1849914b7047be1673039dfbb1e.png 256w,/_next/static/images/5E6oGpSqVAcDPjYT7KjC4S-512-30cc7cafaca6009028ea4312ec76a564.png 512w,/_next/static/images/5E6oGpSqVAcDPjYT7KjC4S-1024-2b8ecaa1d1f13133366ccd3f9b620857.png 1024w,/_next/static/images/5E6oGpSqVAcDPjYT7KjC4S-1074-5f8b3114d12f144928f088b2f7fdff41.png 1074w" alt="Native Bootstrapping "/></picture></div><p class="sc-d57e93a-0 imkcGb sc-2cc3f61e-1 ehDhYc">A policy is pre-trained on the antmaze-large-diverse-v0 D4RL environment with offline data (negative steps correspond to pre-training). We then use the policy to initialize actor-critic fine-tuning (positive steps starting from step 0) with this pre-trained policy as the initial actor. The critic is initialized randomly. The actor’s performance immediately drops and does not recover, as the untrained critic provides a poor learning signal and causes the good initial policy to be forgotten.</p></div><div class="sc-2e5c88b1-0 diiQNG"><p class="sc-d57e93a-0 edIRpA">With the above in mind, in “<a class="sc-2e5c88b1-1 evXWfb" href="https://arxiv.org/abs/2204.02372" target="_blank" rel="noopener noreferrer"><u>Jump-Start Reinforcement Learning</u></a>” (JSRL), we introduce a meta-algorithm that can use a pre-existing policy of any form to initialize any type of RL algorithm. JSRL uses two policies to learn tasks: a <i>guide-policy</i>, and an <i>exploration-policy</i>. The exploration-policy is an RL policy that is trained online with new experience that the agent collects from the environment, and the guide-policy is a pre-existing policy of any form that is not updated during online training. In this work, we focus on scenarios where the guide-policy is learned from demonstrations, but many other kinds of guide-policies can be used. JSRL creates a learning curriculum by rolling in the guide-policy, which is then followed by the self-improving exploration-policy, resulting in performance that compares to or improves on competitive IL+RL methods.</p><h4 class="sc-d2305c5b-0 dSayTV sc-2e5c88b1-2 cLSWOT"><u class="sc-d2305c5b-1 lLzzc">The JSRL Approach</u></h4><p class="sc-d57e93a-0 edIRpA">The guide-policy can take any form: it could be a scripted policy, a policy trained with RL, or even a live human demonstrator. The only requirements are that the guide-policy is reasonable (i.e., better than random exploration), and it can select actions based on observations of the environment. Ideally, the guide-policy can reach poor or medium performance in the environment, but cannot further improve itself with additional fine-tuning. JSRL then allows us to leverage the progress of this guide-policy to take the performance even higher. </p><p class="sc-d57e93a-0 edIRpA">At the beginning of training, we roll out the guide-policy for a fixed number of steps so that the agent is closer to goal states. The exploration-policy then takes over and continues acting in the environment to reach these goals. As the performance of the exploration-policy improves, we gradually reduce the number of steps that the guide-policy takes, until the exploration-policy takes over completely. This process creates a curriculum of starting states for the exploration-policy such that in each curriculum stage, it only needs to learn to reach the initial states of prior curriculum stages.</p></div><div class="sc-e532795e-1 bXjBJo sc-2cc3f61e-0 gyCYJ"><div class="sc-f59e9df7-2 YtoQn sc-e532795e-0 eRDOMB media-wrapper"><video autoplay="" loop="" muted="" playsinline="" aria-label="Guide policy" preload="metadata" disablepictureinpicture="" class="sc-f59e9df7-1 iaNrAz"><source data-src="/_next/static/videos/53rQsCbW99wRQFq7bNjbAB-224806604e4439b81da66503452e45f0.mp4" type="video/mp4"/></video></div><p class="sc-d57e93a-0 imkcGb sc-2cc3f61e-1 ehDhYc">
Here, the task is for the robot arm to pick up the blue block. The guide-policy can move the arm to the block, but it cannot pick it up. It controls the agent until it grips the block, then the exploration-policy takes over, eventually learning to pick up the block. As the exploration-policy improves, the guide-policy controls the agent less and less.
</p></div><div class="sc-2e5c88b1-0 diiQNG"><h4 class="sc-d2305c5b-0 dSayTV sc-2e5c88b1-2 cLSWOT"><u class="sc-d2305c5b-1 lLzzc">Comparison to IL+RL Baselines</u></h4><p class="sc-d57e93a-0 edIRpA">Since JSRL can use a prior policy to initialize RL, a natural comparison would be to <a class="sc-2e5c88b1-1 evXWfb" href="https://arxiv.org/pdf/1811.06711.pdf" target="_blank" rel="noopener noreferrer"><u>imitation</u></a> and reinforcement learning (IL+RL) methods that train on offline datasets, then fine-tune the pre-trained policies with new online experience. We show how JSRL compares to competitive IL+RL methods on the <a class="sc-2e5c88b1-1 evXWfb" href="https://github.com/rail-berkeley/d4rl" target="_blank" rel="noopener noreferrer"><u>D4RL</u></a> benchmark tasks. These tasks include simulated robotic control environments, along with datasets of offline data from human demonstrators, planners, and other learned policies. Out of the <a class="sc-2e5c88b1-1 evXWfb" href="https://github.com/rail-berkeley/d4rl" target="_blank" rel="noopener noreferrer"><u>D4RL</u></a> tasks, we focus on the difficult ant maze and <a class="sc-2e5c88b1-1 evXWfb" href="https://github.com/aravindr93/hand_dapg/" target="_blank" rel="noopener noreferrer"><u>adroit dexterous manipulation</u></a> environments.</p></div><div class="sc-e532795e-1 bXjBJo sc-2cc3f61e-0 gyCYJ"><div class="sc-f59e9df7-2 iRHovN sc-e532795e-0 eRDOMB media-wrapper"><picture class="sc-f59e9df7-0 gGvOxe"><source data-type="image/webp" data-srcset="/_next/static/images/1L0W8IW7nQqHj4hDRtNMEh-64-822ffed5f5192a72e0078779b41260a1.webp 64w,/_next/static/images/1L0W8IW7nQqHj4hDRtNMEh-128-c4d4891713f281d63636db48532758d6.webp 128w,/_next/static/images/1L0W8IW7nQqHj4hDRtNMEh-256-af984066c50df160ae6e0a5a9a219747.webp 256w,/_next/static/images/1L0W8IW7nQqHj4hDRtNMEh-512-3f8b50d064d55bf9a2b1c4b48417ab1a.webp 512w,/_next/static/images/1L0W8IW7nQqHj4hDRtNMEh-642-bc2f9fc9d27261aa50b0f5259bff28e0.webp 642w"/><img data-src="/_next/static/images/1L0W8IW7nQqHj4hDRtNMEh-64-fceeae87169e384fb07173c92b79be1a.png" data-srcset="/_next/static/images/1L0W8IW7nQqHj4hDRtNMEh-64-fceeae87169e384fb07173c92b79be1a.png 64w,/_next/static/images/1L0W8IW7nQqHj4hDRtNMEh-128-be837c1eac8f72f12bb16eeefcf5fa99.png 128w,/_next/static/images/1L0W8IW7nQqHj4hDRtNMEh-256-5e4033754a8ee7edfb4fb36b36a70a76.png 256w,/_next/static/images/1L0W8IW7nQqHj4hDRtNMEh-512-0dcda154f7954052de0c0abc5df30b11.png 512w,/_next/static/images/1L0W8IW7nQqHj4hDRtNMEh-642-957855f5cb8ef13645c6c8d06f3f8543.png 642w" alt="Ant Maze "/></picture></div><p class="sc-d57e93a-0 imkcGb sc-2cc3f61e-1 ehDhYc">Example ant maze (left) and adroit dexterous manipulation (right) environments.</p></div><div class="sc-2e5c88b1-0 diiQNG"><p class="sc-d57e93a-0 edIRpA">For each experiment, we train on an offline dataset and then run online fine-tuning. We compare against algorithms designed specifically for each setting, which include <a class="sc-2e5c88b1-1 evXWfb" href="https://bair.berkeley.edu/blog/2020/09/10/awac/" target="_blank" rel="noopener noreferrer"><u>AWAC</u></a>, <a class="sc-2e5c88b1-1 evXWfb" href="https://github.com/ikostrikov/implicit_q_learning" target="_blank" rel="noopener noreferrer"><u>IQL</u></a>, <a class="sc-2e5c88b1-1 evXWfb" href="https://sites.google.com/corp/view/cql-offline-rl" target="_blank" rel="noopener noreferrer"><u>CQL</u></a>, and <a class="sc-2e5c88b1-1 evXWfb" href="https://link.springer.com/referenceworkentry/10.1007/978-0-387-30164-8_69" target="_blank" rel="noopener noreferrer"><u>behavioral cloning</u></a>. While JSRL can be used in combination with any initial guide-policy or fine-tuning algorithm, we use our strongest baseline, IQL, as a pre-trained guide and for fine-tuning. The full D4RL dataset includes one million offline transitions for each ant maze task. Each transition is a sequence of format (S, A, R, S’) which specifies what state the agent started in (S), the action the agent took (A), the reward the agent received (R), and the state the agent ended up in (S’) after taking action A. We find that JSRL performs well with as few as ten thousand offline transitions.</p></div><div class="sc-e532795e-1 bXjBJo sc-2cc3f61e-0 gyCYJ"><div class="sc-f59e9df7-2 cyoGde sc-e532795e-0 eRDOMB media-wrapper"><picture class="sc-f59e9df7-0 gGvOxe"><source data-type="image/webp" data-srcset="/_next/static/images/4tu6c9gU14Q0L1RmTAgHcK-64-f868baec499a489acdb34ed7b5ae6537.webp 64w,/_next/static/images/4tu6c9gU14Q0L1RmTAgHcK-128-9d2f8f9306e1aaeb7d6d5191bdb042ff.webp 128w,/_next/static/images/4tu6c9gU14Q0L1RmTAgHcK-256-44bafedd3591c1ce8dea00699eeec4c4.webp 256w,/_next/static/images/4tu6c9gU14Q0L1RmTAgHcK-512-2442a9184a7a27609392b5f5ea009524.webp 512w,/_next/static/images/4tu6c9gU14Q0L1RmTAgHcK-1024-b45991c15b368d9640456ec5c2e767f1.webp 1024w,/_next/static/images/4tu6c9gU14Q0L1RmTAgHcK-1074-1415a225678f80a3ec6b65299717c7d8.webp 1074w"/><img data-src="/_next/static/images/4tu6c9gU14Q0L1RmTAgHcK-64-d0b81674629f31e032bd8d4d0f109eb4.png" data-srcset="/_next/static/images/4tu6c9gU14Q0L1RmTAgHcK-64-d0b81674629f31e032bd8d4d0f109eb4.png 64w,/_next/static/images/4tu6c9gU14Q0L1RmTAgHcK-128-0d0ac26b2372a271446b42663b52875e.png 128w,/_next/static/images/4tu6c9gU14Q0L1RmTAgHcK-256-250f135cb9380afc18ca09ca433f1f55.png 256w,/_next/static/images/4tu6c9gU14Q0L1RmTAgHcK-512-6273aebc32a28eb630d6be899e1d18c7.png 512w,/_next/static/images/4tu6c9gU14Q0L1RmTAgHcK-1024-0d0645554688eabaed3613eef1406980.png 1024w,/_next/static/images/4tu6c9gU14Q0L1RmTAgHcK-1074-6a4decd2da0809ba45a8e948027e7e2d.png 1074w" alt="10,000 offline transactions "/></picture></div><p class="sc-d57e93a-0 imkcGb sc-2cc3f61e-1 ehDhYc">10,000 offline transactions </p></div><div class="sc-e532795e-1 bXjBJo sc-2cc3f61e-0 gyCYJ"><div class="sc-f59e9df7-2 cyoGde sc-e532795e-0 eRDOMB media-wrapper"><picture class="sc-f59e9df7-0 gGvOxe"><source data-type="image/webp" data-srcset="/_next/static/images/7GRLg797jFmxm8gBJhcjmp-64-2269e396b6c15b6344d5c5f862e52d60.webp 64w,/_next/static/images/7GRLg797jFmxm8gBJhcjmp-128-ad58c91bb197f95f19efa934182f8623.webp 128w,/_next/static/images/7GRLg797jFmxm8gBJhcjmp-256-9d0a936fd25e5c3dd1652a33e0cd5b90.webp 256w,/_next/static/images/7GRLg797jFmxm8gBJhcjmp-512-e9634639c50a29b92e031b66409110b0.webp 512w,/_next/static/images/7GRLg797jFmxm8gBJhcjmp-1024-224f1ccf47ef0871624c204aa1e09820.webp 1024w,/_next/static/images/7GRLg797jFmxm8gBJhcjmp-1074-bb56559f1849c3f64029fefd4351f845.webp 1074w"/><img data-src="/_next/static/images/7GRLg797jFmxm8gBJhcjmp-64-4e6bff281c027d6886efd25267cffe07.png" data-srcset="/_next/static/images/7GRLg797jFmxm8gBJhcjmp-64-4e6bff281c027d6886efd25267cffe07.png 64w,/_next/static/images/7GRLg797jFmxm8gBJhcjmp-128-360d7b1da07b4316042f0036c7a7cd31.png 128w,/_next/static/images/7GRLg797jFmxm8gBJhcjmp-256-a0b3bd2baa2cfad6ef04f4e26b6b92fc.png 256w,/_next/static/images/7GRLg797jFmxm8gBJhcjmp-512-a3e9bd79ba8ab903702217a2fad2a475.png 512w,/_next/static/images/7GRLg797jFmxm8gBJhcjmp-1024-310fd3f4739e52bb3977b31eda9433f5.png 1024w,/_next/static/images/7GRLg797jFmxm8gBJhcjmp-1074-c00f965b71480c70c7fef3b87b390870.png 1074w" alt="Average score (max=100) on the antmaze-medium-diverse-v0 environment from the D4RL benchmark suite. JSRL can improve even with limited access to offline transitions. "/></picture></div><p class="sc-d57e93a-0 imkcGb sc-2cc3f61e-1 ehDhYc">Average score (max=100) on the antmaze-medium-diverse-v0 environment from the D4RL benchmark suite. JSRL can improve even with limited access to offline transitions. </p></div><div class="sc-2e5c88b1-0 diiQNG"><h4 class="sc-d2305c5b-0 dSayTV sc-2e5c88b1-2 cLSWOT"><u class="sc-d2305c5b-1 lLzzc">Vision-Based Robotic Tasks</u></h4><p class="sc-d57e93a-0 edIRpA">Utilizing offline data is especially challenging in complex tasks such as vision-based robotic manipulation due to the <a class="sc-2e5c88b1-1 evXWfb" href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" target="_blank" rel="noopener noreferrer"><u>curse of dimensionality</u></a>. The high dimensionality of both the continuous-control action space and the pixel-based state space present scaling challenges for IL+RL methods in terms of the amount of data required to learn good policies. To study how JSRL scales to such settings, we focus on two difficult simulated robotic manipulation tasks: <i>indiscriminate grasping</i> (i.e., lifting any object) and <i>instance grasping</i> (i.e., lifting a specific target object).</p></div><div class="sc-e532795e-1 bXjBJo sc-2cc3f61e-0 gyCYJ"><div class="sc-f59e9df7-2 jsrTEH sc-e532795e-0 eRDOMB media-wrapper"><picture class="sc-f59e9df7-0 gGvOxe"><source data-type="image/webp" data-srcset="/_next/static/images/1Df9TTGVrD4nL5Ex1CElgi-64-b19897f232cf0f22b1707ea44b7dc8c1.webp 64w,/_next/static/images/1Df9TTGVrD4nL5Ex1CElgi-128-166f78291bbbd897c96cd6f486fbd3ee.webp 128w,/_next/static/images/1Df9TTGVrD4nL5Ex1CElgi-256-171f1d76dd3630067369ceffe1cad33d.webp 256w,/_next/static/images/1Df9TTGVrD4nL5Ex1CElgi-472-a8719b5a8def65833639a40b6e1ab5eb.webp 472w"/><img data-src="/_next/static/images/1Df9TTGVrD4nL5Ex1CElgi-64-e35fb75ec7ec0bf8b57165ac2c53027c.png" data-srcset="/_next/static/images/1Df9TTGVrD4nL5Ex1CElgi-64-e35fb75ec7ec0bf8b57165ac2c53027c.png 64w,/_next/static/images/1Df9TTGVrD4nL5Ex1CElgi-128-a805bd2ca2196b3adc40efd78abb39d1.png 128w,/_next/static/images/1Df9TTGVrD4nL5Ex1CElgi-256-ead3ba089187bbd3e74cf566ac64cb62.png 256w,/_next/static/images/1Df9TTGVrD4nL5Ex1CElgi-472-b539e7d80aeb9009facf9e026c50b9db.png 472w" alt="A simulated robot arm is placed in front of a table with various categories of objects. When the robot lifts any object, a sparse reward is given for the indiscriminate grasping task. For the instance grasping task, a sparse reward is only given when a specific target object is grasped."/></picture></div><p class="sc-d57e93a-0 imkcGb sc-2cc3f61e-1 ehDhYc">A simulated robot arm is placed in front of a table with various categories of objects. When the robot lifts any object, a sparse reward is given for the indiscriminate grasping task. For the instance grasping task, a sparse reward is only given when a specific target object is grasped.</p></div><div class="sc-2e5c88b1-0 diiQNG"><p class="sc-d57e93a-0 edIRpA">We compare JSRL against methods that are able to scale to complex vision-based robotics settings, such as <a class="sc-2e5c88b1-1 evXWfb" href="https://arxiv.org/abs/1806.10293" target="_blank" rel="noopener noreferrer"><u>QT-Opt</u></a> and <a class="sc-2e5c88b1-1 evXWfb" href="https://openreview.net/forum?id=xwEaXgFa0MR" target="_blank" rel="noopener noreferrer"><u>AW-Opt</u></a>. Each method has access to the same offline dataset of successful demonstrations and is allowed to run online fine-tuning for up to 100,000 steps.</p><p class="sc-d57e93a-0 edIRpA">In these experiments, we use behavioral cloning as a guide-policy and combine JSRL with QT-Opt for fine-tuning. The combination of QT-Opt+JSRL improves faster than all other methods while achieving the highest success rate. </p></div><div class="sc-e532795e-1 bXjBJo sc-2cc3f61e-0 gyCYJ"><div class="sc-f59e9df7-2 cyoGde sc-e532795e-0 eRDOMB media-wrapper"><picture class="sc-f59e9df7-0 gGvOxe"><source data-type="image/webp" data-srcset="/_next/static/images/72HZcMeKwPBrMvxEzfNrOu-64-641230ca7830b5f80236356a43e3dead.webp 64w,/_next/static/images/72HZcMeKwPBrMvxEzfNrOu-128-51cceb3cdbbab2a4cd86e3a8de26c119.webp 128w,/_next/static/images/72HZcMeKwPBrMvxEzfNrOu-256-01d2306f9ecb00095e668948c2ac999c.webp 256w,/_next/static/images/72HZcMeKwPBrMvxEzfNrOu-512-e2d924707c2f7647dd78e399932d04b9.webp 512w,/_next/static/images/72HZcMeKwPBrMvxEzfNrOu-1024-703e96cb6bc8129d7699cd94df3b9615.webp 1024w,/_next/static/images/72HZcMeKwPBrMvxEzfNrOu-1080-1267051ff9de355c770956099897a7b3.webp 1080w"/><img data-src="/_next/static/images/72HZcMeKwPBrMvxEzfNrOu-64-962337a95598ec574452607f339bf82e.png" data-srcset="/_next/static/images/72HZcMeKwPBrMvxEzfNrOu-64-962337a95598ec574452607f339bf82e.png 64w,/_next/static/images/72HZcMeKwPBrMvxEzfNrOu-128-d33fcf389ab6b308b5875e305498df92.png 128w,/_next/static/images/72HZcMeKwPBrMvxEzfNrOu-256-228701548bcaf4880bee92db3f7824a0.png 256w,/_next/static/images/72HZcMeKwPBrMvxEzfNrOu-512-5ad73fe5d47e24d084187f95a8036e51.png 512w,/_next/static/images/72HZcMeKwPBrMvxEzfNrOu-1024-52033a6718fbdd02800949da1f7ce251.png 1024w,/_next/static/images/72HZcMeKwPBrMvxEzfNrOu-1080-c46f5597c2c0c2e3dea6e7844885d36d.png 1080w" alt="Mean grasping success for indiscriminate and instance grasping environments using 2k successful demonstrations. "/></picture></div><p class="sc-d57e93a-0 imkcGb sc-2cc3f61e-1 ehDhYc">Mean grasping success for indiscriminate and instance grasping environments using 2k successful demonstrations. 
</p></div><div class="sc-e532795e-1 bXjBJo sc-2cc3f61e-0 gyCYJ"><div class="sc-f59e9df7-2 cyoGde sc-e532795e-0 eRDOMB media-wrapper"><picture class="sc-f59e9df7-0 gGvOxe"><source data-type="image/webp" data-srcset="/_next/static/images/4dwViNH0sCP3jPHYj6ergk-64-67ea11499848f9e3962810dce2a58f31.webp 64w,/_next/static/images/4dwViNH0sCP3jPHYj6ergk-128-205a6dd2bfb18e328404974490dfb512.webp 128w,/_next/static/images/4dwViNH0sCP3jPHYj6ergk-256-30c72d5dc52f3f123dc86cc67f3da0fb.webp 256w,/_next/static/images/4dwViNH0sCP3jPHYj6ergk-512-6d285edaba8018e66b0833a42ebf3c37.webp 512w,/_next/static/images/4dwViNH0sCP3jPHYj6ergk-1024-51ef1c3419c1018d99ef2d856f8ae9c8.webp 1024w,/_next/static/images/4dwViNH0sCP3jPHYj6ergk-1080-5dac409e992f5b7c991d52a1fb07f449.webp 1080w"/><img data-src="/_next/static/images/4dwViNH0sCP3jPHYj6ergk-64-b735f455e018c345a8b24ebe651f8780.png" data-srcset="/_next/static/images/4dwViNH0sCP3jPHYj6ergk-64-b735f455e018c345a8b24ebe651f8780.png 64w,/_next/static/images/4dwViNH0sCP3jPHYj6ergk-128-2bc6b28be949ce38f2352babad03f966.png 128w,/_next/static/images/4dwViNH0sCP3jPHYj6ergk-256-855b7e20d61d177ef424a8197f80223c.png 256w,/_next/static/images/4dwViNH0sCP3jPHYj6ergk-512-eda707fc395d66bc6387f9d0fb0571db.png 512w,/_next/static/images/4dwViNH0sCP3jPHYj6ergk-1024-9e77f501dca68e26028d7c17d0599e49.png 1024w,/_next/static/images/4dwViNH0sCP3jPHYj6ergk-1080-aeb5af4ea4a43d54ce27f101a4f1503e.png 1080w" alt="Mean grasping success for indiscriminate grasping environments using 2k successful demonstrations. "/></picture></div><p class="sc-d57e93a-0 imkcGb sc-2cc3f61e-1 ehDhYc">Mean grasping success for indiscriminate grasping environments using 2k successful demonstrations. </p></div><div class="sc-2e5c88b1-0 diiQNG"><h4 class="sc-d2305c5b-0 dSayTV sc-2e5c88b1-2 cLSWOT"><u class="sc-d2305c5b-1 lLzzc">Conclusion</u></h4><p class="sc-d57e93a-0 edIRpA">We proposed JSRL, a method for leveraging a prior policy of any form to improve exploration for initializing RL tasks. Our algorithm creates a learning curriculum by rolling in a pre-existing guide-policy, which is then followed by the self-improving exploration-policy. The job of the exploration-policy is greatly simplified since it starts exploring from states closer to the goal. As the exploration-policy improves, the effect of the guide-policy diminishes, leading to a fully capable RL policy. In the future, we plan to apply JSRL to problems such as <a class="sc-2e5c88b1-1 evXWfb" href="https://arxiv.org/pdf/2009.13303.pdf" target="_blank" rel="noopener noreferrer"><u>Sim2Real</u></a>, and explore how we can leverage multiple guide-policies to train RL agents.</p><p class="sc-d57e93a-0 edIRpA"><b>Acknowledgements</b>
<i>This work would not have been possible without Ikechukwu Uchendu, Ted Xiao, Yao Lu, Banghua Zhu, Mengyuan Yan, Joséphine Simon, Matthew Bennice, Chuyuan Fu, Cong Ma, Jiantao Jiao, Sergey Levine, and Karol Hausman. Special thanks to Tom Small for creating the animations for this post.</i></p></div><div class="sc-fdb2fb33-1 iAArmB"><div class="sc-34174fa0-0 fkCieZ"><p class="sc-d57e93a-0 jZunqb sc-34174fa0-1 ksIrsv">Links</p><div class="sc-13cee2ed-0 bDBNNm sc-34174fa0-3 iWhknh"><div class="sc-faf29a58-0 kYodSY sc-13cee2ed-1 kCikXL icon-wrapper"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 22 22" width="100%" height="100%"><path fill="#000" fill-rule="evenodd" d="M14.536 11l3.182-3.183a2.5 2.5 0 10-3.536-3.535L11 7.464 12.237 8.7l1.061-1.06 1.06 1.06-1.06 1.06L14.536 11zm-2.299-.178l1.238 1.238 1.06 1.06 1.061-1.06 3.182-3.182a4 4 0 00-5.657-5.657L9.94 6.403l-1.06 1.06 1.06 1.061 1.238 1.238-1.414 1.414-1.238-1.237-1.06-1.061-1.061 1.06-3.182 3.182a4 4 0 005.657 5.657l3.182-3.182 1.06-1.06-1.06-1.06-1.238-1.238 1.414-1.415zm-3.535 1.415l-1.06 1.06 1.06 1.06 1.06-1.06L11 14.535l-3.182 3.182a2.5 2.5 0 01-3.536-3.536L7.464 11l1.238 1.238z" clip-rule="evenodd"></path></svg></div><div class="sc-13cee2ed-2 jinLpX"><a class="sc-13cee2ed-3 xdiVk" href="https://ai.googleblog.com/2022/04/efficiently-initializing-reinforcement.html" target="_blank" rel="noopener noreferrer">Google AI Blog Efficiently Initializing Reinforcement Learning With Prior Policies</a></div></div><div class="sc-13cee2ed-0 bDBNNm sc-34174fa0-3 iWhknh"><div class="sc-faf29a58-0 kYodSY sc-13cee2ed-1 kCikXL icon-wrapper"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 22 22" width="100%" height="100%"><path fill="#000" fill-rule="evenodd" d="M14.536 11l3.182-3.183a2.5 2.5 0 10-3.536-3.535L11 7.464 12.237 8.7l1.061-1.06 1.06 1.06-1.06 1.06L14.536 11zm-2.299-.178l1.238 1.238 1.06 1.06 1.061-1.06 3.182-3.182a4 4 0 00-5.657-5.657L9.94 6.403l-1.06 1.06 1.06 1.061 1.238 1.238-1.414 1.414-1.238-1.237-1.06-1.061-1.061 1.06-3.182 3.182a4 4 0 005.657 5.657l3.182-3.182 1.06-1.06-1.06-1.06-1.238-1.238 1.414-1.415zm-3.535 1.415l-1.06 1.06 1.06 1.06 1.06-1.06L11 14.535l-3.182 3.182a2.5 2.5 0 01-3.536-3.536L7.464 11l1.238 1.238z" clip-rule="evenodd"></path></svg></div><div class="sc-13cee2ed-2 jinLpX"><a class="sc-13cee2ed-3 xdiVk" href="https://github.com/aravindr93/hand_dapg/" target="_blank" rel="noopener noreferrer">Androit manipulation suite </a></div></div><div class="sc-13cee2ed-0 bDBNNm sc-34174fa0-3 iWhknh"><div class="sc-faf29a58-0 kYodSY sc-13cee2ed-1 kCikXL icon-wrapper"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 22 22" width="100%" height="100%"><path fill="#000" fill-rule="evenodd" d="M14.536 11l3.182-3.183a2.5 2.5 0 10-3.536-3.535L11 7.464 12.237 8.7l1.061-1.06 1.06 1.06-1.06 1.06L14.536 11zm-2.299-.178l1.238 1.238 1.06 1.06 1.061-1.06 3.182-3.182a4 4 0 00-5.657-5.657L9.94 6.403l-1.06 1.06 1.06 1.061 1.238 1.238-1.414 1.414-1.238-1.237-1.06-1.061-1.061 1.06-3.182 3.182a4 4 0 005.657 5.657l3.182-3.182 1.06-1.06-1.06-1.06-1.238-1.238 1.414-1.415zm-3.535 1.415l-1.06 1.06 1.06 1.06 1.06-1.06L11 14.535l-3.182 3.182a2.5 2.5 0 01-3.536-3.536L7.464 11l1.238 1.238z" clip-rule="evenodd"></path></svg></div><div class="sc-13cee2ed-2 jinLpX"><a class="sc-13cee2ed-3 xdiVk" href="https://en.wikipedia.org/wiki/Reinforcement_learning" target="_blank" rel="noopener noreferrer">Reinforcement learning - Wikipedia</a></div></div><div class="sc-13cee2ed-0 bDBNNm sc-34174fa0-3 iWhknh"><div class="sc-faf29a58-0 kYodSY sc-13cee2ed-1 kCikXL icon-wrapper"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 22 22" width="100%" height="100%"><path fill="#000" fill-rule="evenodd" d="M14.536 11l3.182-3.183a2.5 2.5 0 10-3.536-3.535L11 7.464 12.237 8.7l1.061-1.06 1.06 1.06-1.06 1.06L14.536 11zm-2.299-.178l1.238 1.238 1.06 1.06 1.061-1.06 3.182-3.182a4 4 0 00-5.657-5.657L9.94 6.403l-1.06 1.06 1.06 1.061 1.238 1.238-1.414 1.414-1.238-1.237-1.06-1.061-1.061 1.06-3.182 3.182a4 4 0 005.657 5.657l3.182-3.182 1.06-1.06-1.06-1.06-1.238-1.238 1.414-1.415zm-3.535 1.415l-1.06 1.06 1.06 1.06 1.06-1.06L11 14.535l-3.182 3.182a2.5 2.5 0 01-3.536-3.536L7.464 11l1.238 1.238z" clip-rule="evenodd"></path></svg></div><div class="sc-13cee2ed-2 jinLpX"><a class="sc-13cee2ed-3 xdiVk" href="https://en.wikipedia.org/wiki/Value_function" target="_blank" rel="noopener noreferrer">Value-based RL wiki page</a></div></div><div class="sc-13cee2ed-0 bDBNNm sc-34174fa0-3 iWhknh"><div class="sc-faf29a58-0 kYodSY sc-13cee2ed-1 kCikXL icon-wrapper"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 22 22" width="100%" height="100%"><path fill="#000" fill-rule="evenodd" d="M14.536 11l3.182-3.183a2.5 2.5 0 10-3.536-3.535L11 7.464 12.237 8.7l1.061-1.06 1.06 1.06-1.06 1.06L14.536 11zm-2.299-.178l1.238 1.238 1.06 1.06 1.061-1.06 3.182-3.182a4 4 0 00-5.657-5.657L9.94 6.403l-1.06 1.06 1.06 1.061 1.238 1.238-1.414 1.414-1.238-1.237-1.06-1.061-1.061 1.06-3.182 3.182a4 4 0 005.657 5.657l3.182-3.182 1.06-1.06-1.06-1.06-1.238-1.238 1.414-1.415zm-3.535 1.415l-1.06 1.06 1.06 1.06 1.06-1.06L11 14.535l-3.182 3.182a2.5 2.5 0 01-3.536-3.536L7.464 11l1.238 1.238z" clip-rule="evenodd"></path></svg></div><div class="sc-13cee2ed-2 jinLpX"><a class="sc-13cee2ed-3 xdiVk" href="https://arxiv.org/abs/2204.02372" target="_blank" rel="noopener noreferrer">Jump-start RL Learning Arxiv Paper</a></div></div><div class="sc-13cee2ed-0 bDBNNm sc-34174fa0-3 iWhknh"><div class="sc-faf29a58-0 kYodSY sc-13cee2ed-1 kCikXL icon-wrapper"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 22 22" width="100%" height="100%"><path fill="#000" fill-rule="evenodd" d="M14.536 11l3.182-3.183a2.5 2.5 0 10-3.536-3.535L11 7.464 12.237 8.7l1.061-1.06 1.06 1.06-1.06 1.06L14.536 11zm-2.299-.178l1.238 1.238 1.06 1.06 1.061-1.06 3.182-3.182a4 4 0 00-5.657-5.657L9.94 6.403l-1.06 1.06 1.06 1.061 1.238 1.238-1.414 1.414-1.238-1.237-1.06-1.061-1.061 1.06-3.182 3.182a4 4 0 005.657 5.657l3.182-3.182 1.06-1.06-1.06-1.06-1.238-1.238 1.414-1.415zm-3.535 1.415l-1.06 1.06 1.06 1.06 1.06-1.06L11 14.535l-3.182 3.182a2.5 2.5 0 01-3.536-3.536L7.464 11l1.238 1.238z" clip-rule="evenodd"></path></svg></div><div class="sc-13cee2ed-2 jinLpX"><a class="sc-13cee2ed-3 xdiVk" href="https://github.com/rail-berkeley/d4rl" target="_blank" rel="noopener noreferrer">D45L Github page</a></div></div><div class="sc-13cee2ed-0 bDBNNm sc-34174fa0-3 iWhknh"><div class="sc-faf29a58-0 kYodSY sc-13cee2ed-1 kCikXL icon-wrapper"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 22 22" width="100%" height="100%"><path fill="#000" fill-rule="evenodd" d="M14.536 11l3.182-3.183a2.5 2.5 0 10-3.536-3.535L11 7.464 12.237 8.7l1.061-1.06 1.06 1.06-1.06 1.06L14.536 11zm-2.299-.178l1.238 1.238 1.06 1.06 1.061-1.06 3.182-3.182a4 4 0 00-5.657-5.657L9.94 6.403l-1.06 1.06 1.06 1.061 1.238 1.238-1.414 1.414-1.238-1.237-1.06-1.061-1.061 1.06-3.182 3.182a4 4 0 005.657 5.657l3.182-3.182 1.06-1.06-1.06-1.06-1.238-1.238 1.414-1.415zm-3.535 1.415l-1.06 1.06 1.06 1.06 1.06-1.06L11 14.535l-3.182 3.182a2.5 2.5 0 01-3.536-3.536L7.464 11l1.238 1.238z" clip-rule="evenodd"></path></svg></div><div class="sc-13cee2ed-2 jinLpX"><a class="sc-13cee2ed-3 xdiVk" href="https://arxiv.org/pdf/1811.06711.pdf" target="_blank" rel="noopener noreferrer">An Algorithmic Perspective on Imitation Learning - arXiv</a></div></div><div class="sc-13cee2ed-0 bDBNNm sc-34174fa0-3 iWhknh"><div class="sc-faf29a58-0 kYodSY sc-13cee2ed-1 kCikXL icon-wrapper"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 22 22" width="100%" height="100%"><path fill="#000" fill-rule="evenodd" d="M14.536 11l3.182-3.183a2.5 2.5 0 10-3.536-3.535L11 7.464 12.237 8.7l1.061-1.06 1.06 1.06-1.06 1.06L14.536 11zm-2.299-.178l1.238 1.238 1.06 1.06 1.061-1.06 3.182-3.182a4 4 0 00-5.657-5.657L9.94 6.403l-1.06 1.06 1.06 1.061 1.238 1.238-1.414 1.414-1.238-1.237-1.06-1.061-1.061 1.06-3.182 3.182a4 4 0 005.657 5.657l3.182-3.182 1.06-1.06-1.06-1.06-1.238-1.238 1.414-1.415zm-3.535 1.415l-1.06 1.06 1.06 1.06 1.06-1.06L11 14.535l-3.182 3.182a2.5 2.5 0 01-3.536-3.536L7.464 11l1.238 1.238z" clip-rule="evenodd"></path></svg></div><div class="sc-13cee2ed-2 jinLpX"><a class="sc-13cee2ed-3 xdiVk" href="https://link.springer.com/referenceworkentry/10.1007/978-0-387-30164-8_69" target="_blank" rel="noopener noreferrer">Behavioral Cloning </a></div></div><div class="sc-13cee2ed-0 bDBNNm sc-34174fa0-3 iWhknh"><div class="sc-faf29a58-0 kYodSY sc-13cee2ed-1 kCikXL icon-wrapper"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 22 22" width="100%" height="100%"><path fill="#000" fill-rule="evenodd" d="M14.536 11l3.182-3.183a2.5 2.5 0 10-3.536-3.535L11 7.464 12.237 8.7l1.061-1.06 1.06 1.06-1.06 1.06L14.536 11zm-2.299-.178l1.238 1.238 1.06 1.06 1.061-1.06 3.182-3.182a4 4 0 00-5.657-5.657L9.94 6.403l-1.06 1.06 1.06 1.061 1.238 1.238-1.414 1.414-1.238-1.237-1.06-1.061-1.061 1.06-3.182 3.182a4 4 0 005.657 5.657l3.182-3.182 1.06-1.06-1.06-1.06-1.238-1.238 1.414-1.415zm-3.535 1.415l-1.06 1.06 1.06 1.06 1.06-1.06L11 14.535l-3.182 3.182a2.5 2.5 0 01-3.536-3.536L7.464 11l1.238 1.238z" clip-rule="evenodd"></path></svg></div><div class="sc-13cee2ed-2 jinLpX"><a class="sc-13cee2ed-3 xdiVk" href="https://sites.google.com/corp/view/cql-offline-rl" target="_blank" rel="noopener noreferrer">CQL </a></div></div><div class="sc-13cee2ed-0 bDBNNm sc-34174fa0-3 iWhknh"><div class="sc-faf29a58-0 kYodSY sc-13cee2ed-1 kCikXL icon-wrapper"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 22 22" width="100%" height="100%"><path fill="#000" fill-rule="evenodd" d="M14.536 11l3.182-3.183a2.5 2.5 0 10-3.536-3.535L11 7.464 12.237 8.7l1.061-1.06 1.06 1.06-1.06 1.06L14.536 11zm-2.299-.178l1.238 1.238 1.06 1.06 1.061-1.06 3.182-3.182a4 4 0 00-5.657-5.657L9.94 6.403l-1.06 1.06 1.06 1.061 1.238 1.238-1.414 1.414-1.238-1.237-1.06-1.061-1.061 1.06-3.182 3.182a4 4 0 005.657 5.657l3.182-3.182 1.06-1.06-1.06-1.06-1.238-1.238 1.414-1.415zm-3.535 1.415l-1.06 1.06 1.06 1.06 1.06-1.06L11 14.535l-3.182 3.182a2.5 2.5 0 01-3.536-3.536L7.464 11l1.238 1.238z" clip-rule="evenodd"></path></svg></div><div class="sc-13cee2ed-2 jinLpX"><a class="sc-13cee2ed-3 xdiVk" href="https://github.com/ikostrikov/implicit_q_learning" target="_blank" rel="noopener noreferrer">IQL Git hub</a></div></div><div class="sc-13cee2ed-0 bDBNNm sc-34174fa0-3 iWhknh"><div class="sc-faf29a58-0 kYodSY sc-13cee2ed-1 kCikXL icon-wrapper"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 22 22" width="100%" height="100%"><path fill="#000" fill-rule="evenodd" d="M14.536 11l3.182-3.183a2.5 2.5 0 10-3.536-3.535L11 7.464 12.237 8.7l1.061-1.06 1.06 1.06-1.06 1.06L14.536 11zm-2.299-.178l1.238 1.238 1.06 1.06 1.061-1.06 3.182-3.182a4 4 0 00-5.657-5.657L9.94 6.403l-1.06 1.06 1.06 1.061 1.238 1.238-1.414 1.414-1.238-1.237-1.06-1.061-1.061 1.06-3.182 3.182a4 4 0 005.657 5.657l3.182-3.182 1.06-1.06-1.06-1.06-1.238-1.238 1.414-1.415zm-3.535 1.415l-1.06 1.06 1.06 1.06 1.06-1.06L11 14.535l-3.182 3.182a2.5 2.5 0 01-3.536-3.536L7.464 11l1.238 1.238z" clip-rule="evenodd"></path></svg></div><div class="sc-13cee2ed-2 jinLpX"><a class="sc-13cee2ed-3 xdiVk" href="https://bair.berkeley.edu/blog/2020/09/10/awac/" target="_blank" rel="noopener noreferrer">AWAC: Accelerating Online Reinforcement Learning with Offline Datasets</a></div></div><div class="sc-13cee2ed-0 bDBNNm sc-34174fa0-3 iWhknh"><div class="sc-faf29a58-0 kYodSY sc-13cee2ed-1 kCikXL icon-wrapper"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 22 22" width="100%" height="100%"><path fill="#000" fill-rule="evenodd" d="M14.536 11l3.182-3.183a2.5 2.5 0 10-3.536-3.535L11 7.464 12.237 8.7l1.061-1.06 1.06 1.06-1.06 1.06L14.536 11zm-2.299-.178l1.238 1.238 1.06 1.06 1.061-1.06 3.182-3.182a4 4 0 00-5.657-5.657L9.94 6.403l-1.06 1.06 1.06 1.061 1.238 1.238-1.414 1.414-1.238-1.237-1.06-1.061-1.061 1.06-3.182 3.182a4 4 0 005.657 5.657l3.182-3.182 1.06-1.06-1.06-1.06-1.238-1.238 1.414-1.415zm-3.535 1.415l-1.06 1.06 1.06 1.06 1.06-1.06L11 14.535l-3.182 3.182a2.5 2.5 0 01-3.536-3.536L7.464 11l1.238 1.238z" clip-rule="evenodd"></path></svg></div><div class="sc-13cee2ed-2 jinLpX"><a class="sc-13cee2ed-3 xdiVk" href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" target="_blank" rel="noopener noreferrer">Curse of dimensionality </a></div></div><div class="sc-13cee2ed-0 bDBNNm sc-34174fa0-3 iWhknh"><div class="sc-faf29a58-0 kYodSY sc-13cee2ed-1 kCikXL icon-wrapper"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 22 22" width="100%" height="100%"><path fill="#000" fill-rule="evenodd" d="M14.536 11l3.182-3.183a2.5 2.5 0 10-3.536-3.535L11 7.464 12.237 8.7l1.061-1.06 1.06 1.06-1.06 1.06L14.536 11zm-2.299-.178l1.238 1.238 1.06 1.06 1.061-1.06 3.182-3.182a4 4 0 00-5.657-5.657L9.94 6.403l-1.06 1.06 1.06 1.061 1.238 1.238-1.414 1.414-1.238-1.237-1.06-1.061-1.061 1.06-3.182 3.182a4 4 0 005.657 5.657l3.182-3.182 1.06-1.06-1.06-1.06-1.238-1.238 1.414-1.415zm-3.535 1.415l-1.06 1.06 1.06 1.06 1.06-1.06L11 14.535l-3.182 3.182a2.5 2.5 0 01-3.536-3.536L7.464 11l1.238 1.238z" clip-rule="evenodd"></path></svg></div><div class="sc-13cee2ed-2 jinLpX"><a class="sc-13cee2ed-3 xdiVk" href="https://openreview.net/forum?id=xwEaXgFa0MR" target="_blank" rel="noopener noreferrer">AW-Opt: Learning Robotic Skills with Imitation and Reinforcement at Scale</a></div></div><div class="sc-13cee2ed-0 bDBNNm sc-34174fa0-3 iWhknh"><div class="sc-faf29a58-0 kYodSY sc-13cee2ed-1 kCikXL icon-wrapper"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 22 22" width="100%" height="100%"><path fill="#000" fill-rule="evenodd" d="M14.536 11l3.182-3.183a2.5 2.5 0 10-3.536-3.535L11 7.464 12.237 8.7l1.061-1.06 1.06 1.06-1.06 1.06L14.536 11zm-2.299-.178l1.238 1.238 1.06 1.06 1.061-1.06 3.182-3.182a4 4 0 00-5.657-5.657L9.94 6.403l-1.06 1.06 1.06 1.061 1.238 1.238-1.414 1.414-1.238-1.237-1.06-1.061-1.061 1.06-3.182 3.182a4 4 0 005.657 5.657l3.182-3.182 1.06-1.06-1.06-1.06-1.238-1.238 1.414-1.415zm-3.535 1.415l-1.06 1.06 1.06 1.06 1.06-1.06L11 14.535l-3.182 3.182a2.5 2.5 0 01-3.536-3.536L7.464 11l1.238 1.238z" clip-rule="evenodd"></path></svg></div><div class="sc-13cee2ed-2 jinLpX"><a class="sc-13cee2ed-3 xdiVk" href="https://arxiv.org/abs/1806.10293" target="_blank" rel="noopener noreferrer">QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation - arXiv</a></div></div><div class="sc-13cee2ed-0 bDBNNm sc-34174fa0-3 iWhknh"><div class="sc-faf29a58-0 kYodSY sc-13cee2ed-1 kCikXL icon-wrapper"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 22 22" width="100%" height="100%"><path fill="#000" fill-rule="evenodd" d="M14.536 11l3.182-3.183a2.5 2.5 0 10-3.536-3.535L11 7.464 12.237 8.7l1.061-1.06 1.06 1.06-1.06 1.06L14.536 11zm-2.299-.178l1.238 1.238 1.06 1.06 1.061-1.06 3.182-3.182a4 4 0 00-5.657-5.657L9.94 6.403l-1.06 1.06 1.06 1.061 1.238 1.238-1.414 1.414-1.238-1.237-1.06-1.061-1.061 1.06-3.182 3.182a4 4 0 005.657 5.657l3.182-3.182 1.06-1.06-1.06-1.06-1.238-1.238 1.414-1.415zm-3.535 1.415l-1.06 1.06 1.06 1.06 1.06-1.06L11 14.535l-3.182 3.182a2.5 2.5 0 01-3.536-3.536L7.464 11l1.238 1.238z" clip-rule="evenodd"></path></svg></div><div class="sc-13cee2ed-2 jinLpX"><a class="sc-13cee2ed-3 xdiVk" href="https://arxiv.org/pdf/2009.13303.pdf" target="_blank" rel="noopener noreferrer">Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: a Survey</a></div></div></div><div class="sc-d11d9e57-0 jbhrap"><p class="sc-d57e93a-0 jZunqb sc-d11d9e57-2 cjHfXU">Topics</p><div class="sc-d11d9e57-1 jzZCjv"><a class="sc-886f2911-1 iNInRn" href="archive/news.html">News</a><a class="sc-886f2911-1 iNInRn" href="archive/research.html">Research</a></div></div></div></div></div></div><footer id="page-footer" class="sc-bc2a2328-0 ikUERX"><div class="sc-bc2a2328-1 fLIUiz"><div class="sc-bc2a2328-2 kuSqiN"><a class="sc-37c0da59-0 laHiNe sc-bc2a2328-3 kOsgKR" aria-label="Everyday Robots logo" href="../index.html"><svg class="sc-147f2498-0 ZkFrP" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 137 50" fill="#ffffff"><defs><clipPath id="top-line-clip"><rect x="0" y="0" width="100%" height="65%"></rect></clipPath><clipPath id="bottom-line-clip"><rect x="0" y="50%" width="100%" height="50%"></rect></clipPath></defs><g clip-path="url(#top-line-clip)"><g><path d="M17.3912.1155V5.175H6.2602v3.7097h10.1774v5.2144H6.2602v4.0946h11.131v5.3695H0V.1155h17.3912Z"></path><path d="m23.9297 23.5627-6.773-17.3833h6.3372l3.4095 9.9641 3.348-9.964h6.1013l-6.8345 17.3832h-5.5885Z"></path><path d="M52.1088 17.4983c-.6307 3.9996-3.7223 6.4493-8.3573 6.4493-5.4655 0-9.0699-3.6696-9.0699-9.0791 0-5.4094 3.8044-9.074 8.952-9.074 5.4655 0 8.5572 3.5546 8.5572 8.7291v1.4998H40.6599c.1999 2.0848 1.3074 3.2097 3.0763 3.2097 1.2664 0 2.261-.545 2.6148-1.7398l5.7578.005Zm-11.3259-4.4996h5.363c-.0769-1.4298-.9895-2.4997-2.5328-2.4997-1.4458 0-2.4354.8949-2.8302 2.4997Z"></path><path d="M64.7609 11.9337a4.894 4.894 0 0 0-2.3995-.5399c-1.7022 0-2.5636.7199-3.0148 1.9698v10.1989h-6.2192V6.1793h6.2192V7.724c.7281-1.2649 1.9278-1.9298 3.7121-1.9298a3.9422 3.9422 0 0 1 1.7022.31v5.8294Z"></path><path d="m69.3421 28.8522 2.3225-5.7144-6.3268-16.9584h6.4448l3.0762 9.5691 2.9994-9.569h6.1833l-8.5623 22.6727h-6.1371Z"></path><path d="M95.1963 22.1728a6.2166 6.2166 0 0 1-2.018 1.3153 6.3427 6.3427 0 0 1-2.381.4595c-5.1272 0-7.9625-4.0546-7.9625-9.0791 0-5.0245 2.8148-9.074 7.9625-9.074a6.3418 6.3418 0 0 1 2.381.4595 6.216 6.216 0 0 1 2.018 1.3153V0h6.2197v23.5627h-6.2197v-1.3899Zm0-9.619c-.2587-.4893-.6506-.8997-1.1326-1.1863a3.1357 3.1357 0 0 0-1.6001-.4386c-2.138 0-3.4096 1.6998-3.4096 3.9396s1.2716 3.9046 3.4096 3.9046a3.0517 3.0517 0 0 0 1.6077-.4264c.4837-.2877.8738-.7032 1.125-1.1984v-4.5945Z"></path><path d="M113.12 23.6178v-.8849c-.594.58-2.379 1.1949-4.281 1.1949-3.527 0-6.496-1.9298-6.496-5.5994 0-3.3597 2.969-5.4995 6.855-5.4995 1.467 0 3.205.465 3.922.9649v-1.1449a1.9004 1.9004 0 0 0-.125-.8304 1.9406 1.9406 0 0 0-.47-.7027 2.0065 2.0065 0 0 0-.73-.4455 2.05 2.05 0 0 0-.854-.1062c-1.148 0-1.825.5-2.102 1.2749h-5.86c.513-3.3597 3.589-5.9994 8.157-5.9994 5.071 0 7.963 2.6247 7.963 7.1443v10.6339h-5.979Zm0-5.8694c-.399-.7349-1.466-1.1949-2.614-1.1949-1.231 0-2.456.5-2.456 1.6599s1.225 1.6998 2.456 1.6998c1.148 0 2.215-.4649 2.614-1.1599v-1.0049Z"></path><path d="m122.311 28.8522 2.322-5.7144-6.327-16.9584h6.46l3.077 9.5691 3.004-9.569H137l-8.547 22.6727h-6.142Z"></path></g></g><g clip-path="url(#bottom-line-clip)"><g><path d="M6.3448 41.9608V49.53H.0436V26.0824h10.9361c5.2246 0 8.8341 2.8997 8.8341 8.0742 0 3.5946-1.8663 6.0644-4.8349 7.1442l5.7014 8.2292h-7.0498l-5.0708-7.5692H6.3448Zm0-4.9445h3.9582c2.261 0 3.2865-1.1199 3.2865-2.8597 0-1.7399-1.0255-2.8598-3.2865-2.8598H6.3448v5.7195Z"></path><path d="M28.7099 31.7618c-1.8509-.005-3.6617.5258-5.2031 1.525-1.5414.9992-2.744 2.422-3.4556 4.0881-.7116 1.6662-.9002 3.5007-.5418 5.2715.3583 1.7707 1.2475 3.3979 2.5548 4.6755 1.3074 1.2776 2.9742 2.1482 4.7893 2.5016 1.8151.3533 3.697.1734 5.4072-.5168 1.7103-.6902 3.172-1.8598 4.2001-3.3606 1.0281-1.5008 1.5764-3.2654 1.5754-5.0703-.0014-2.4133-.9837-4.7277-2.7319-6.4361-1.7481-1.7083-4.1194-2.6713-6.5944-2.6779Zm0 13.2336c-1.6509 0-2.9891-1.4298-2.9891-4.1396 0-2.7097 1.3177-4.1095 2.9891-4.1095 1.6715 0 2.9891 1.4248 2.9891 4.1295 0 2.7048-1.3586 4.1196-2.9891 4.1196Z"></path><path d="M45.1226 49.5302H38.924V25.9976h6.1986v7.4992c1.1673-1.1366 2.7495-1.775 4.3991-1.7748 5.1272 0 7.9625 4.0546 7.9625 9.0791 0 5.0245-2.8097 9.0741-7.9625 9.0741-1.6437.0108-3.2251-.6128-4.3991-1.7348v1.3898Zm0-6.4143c.2511.4963.6419.9127 1.1268 1.2005a3.0474 3.0474 0 0 0 1.6111.4243c2.138 0 3.4044-1.6598 3.4044-3.8996s-1.2664-3.9396-3.4044-3.9396a3.1757 3.1757 0 0 0-1.5985.4409c-.4822.2852-.8759.6927-1.1394 1.1789v4.5946Z"></path><path d="M67.815 31.7617c-1.8498 0-3.6581.535-5.1961 1.5372-1.5381 1.0022-2.7367 2.4268-3.4444 4.0933-.7077 1.6666-.8926 3.5004-.5313 5.2695.3613 1.7691 1.2525 3.3939 2.5609 4.669 1.3084 1.2752 2.9752 2.1433 4.7896 2.4946 1.8144.3513 3.695.17 5.4037-.521 1.7088-.691 3.169-1.8606 4.1959-3.3608 1.027-1.5003 1.5746-3.2639 1.5736-5.0677-.0013-2.4177-.9872-4.7359-2.7409-6.4449-1.7537-1.7091-4.1316-2.6692-6.611-2.6692Zm0 13.2537c-1.6509 0-2.9891-1.4299-2.9891-4.1396 0-2.7097 1.3382-4.1296 2.9891-4.1296 1.651 0 2.9943 1.4249 2.9943 4.1296s-1.3433 4.1196-2.9943 4.1196v.02Z"></path><path d="M88.3709 32.147v4.7145h-2.6046v12.6687h-6.1372V36.8615h-2.6097V32.147h2.6097v-3.9746h6.1372v3.9746h2.6046Z"></path><path d="M94.8537 44.1606c.1437.4637.4459.8655.8564 1.1384a2.2163 2.2163 0 0 0 1.3996.3615c1.0254 0 1.8201-.385 1.8201-1.1949 0-.655-.5127-.8899-1.3843-1.0799l-3.4865-.7c-2.9686-.6149-4.9118-1.9998-4.9118-5.0594 0-3.7047 3.4096-5.8695 7.6087-5.8695 4.8711 0 7.5271 2.1998 8.0801 5.6395h-5.7524c-.1948-.73-.7486-1.3999-2.179-1.3999-.9075 0-1.6612.385-1.6612 1.1599 0 .5399.3948.8099 1.2254.9649l3.512.8249c3.2502.7349 4.9942 2.3948 4.9942 5.2145 0 3.7096-3.451 5.7544-7.8038 5.7544-4.558 0-7.8445-1.9998-8.3983-5.7544h6.0808Z"></path></g></g></svg></a><div class="sc-93a65f79-0 gnODzT"><a class="sc-b87c5082-0 hFMTuV" href="https://www.linkedin.com/company/everydayrobots/" target="_blank" rel="noopener noreferrer" aria-label="Linkedin" tabindex="0"><div class="sc-faf29a58-0 cBpQkk icon-wrapper"><svg viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg" width="100%" height="100%"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.278 0C.572 0 0 .572 0 1.278v15.444C0 17.428.572 18 1.278 18h15.444c.706 0 1.278-.572 1.278-1.278V1.278C18 .572 17.428 0 16.722 0H1.278zM4.04 5.59a1.562 1.562 0 100-3.123 1.562 1.562 0 000 3.123zm2.992 1.154H9.62v1.185s.702-1.404 2.613-1.404c1.704 0 3.116.84 3.116 3.399v5.397h-2.682v-4.743c0-1.51-.806-1.676-1.42-1.676-1.275 0-1.493 1.1-1.493 1.873v4.546H7.032V6.744zm-1.63 0H2.678v8.577h2.722V6.744z" fill="#000"></path></svg></div></a></div></div><div class="sc-bc2a2328-4 hpdLBx"><a class="sc-bc2a2328-5 ecIfRF" href="../index.html">Home</a><a class="sc-bc2a2328-5 gQMvHh" href="../journey.html">Journey</a><a class="sc-bc2a2328-5 wsigZ" href="../technology.html">Technology</a><a class="sc-bc2a2328-5 cGRCnN" href="../team.html">Team</a><a class="sc-bc2a2328-5 hBLclq" href="../vision.html">Vision</a><a class="sc-bc2a2328-5 kpyAym" href="../thinking.html">Thinking</a><a class="sc-bc2a2328-5 dUNvvy" href="../join-us.html">Join us</a><a class="sc-bc2a2328-5 cEMzPg" href="../connect.html">Connect</a><a class="sc-bc2a2328-5 eXGrwc" href="https://policies.google.com/" target="_blank" rel="noopener noreferrer">Privacy &amp; Terms</a><a class="sc-bc2a2328-5 glKgEY" href="https://about.google/" target="_blank" rel="noopener noreferrer">Google</a><a class="sc-bc2a2328-5 ePTDbg" href="https://abc.xyz/" target="_blank" rel="noopener noreferrer">Alphabet</a></div></div><p class="sc-d57e93a-0 imkcGb sc-bc2a2328-6 lkNUFO">Copyright 2022 X Development LLC. All rights reserved.</p></footer></div></main><div class="sc-efd73938-0 jUoqXe"></div><noscript><iframe class="gtm-iframe" src="https://www.googletagmanager.com/ns.html?id=GTM-5XF52G2" height="0" width="0"></iframe></noscript></div><script nonce="qqZu5p16uR" id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"globals":{"siteTitle":"Everyday Robots","titleTemplate":"[pageTitle] | [siteTitle]","siteDescription":"Born from X, and working alongside teams at Google, we’re building a new type of robot. One that can learn by itself, to help anyone with (almost) anything.","baseSiteUrl":"https://everydayrobots.com","shareAsset":{"title":"Everyday Robots","url":"https://images.ctfassets.net/1ejv5e8uweut/75uzlMeOlBEoNmGkZ5uRrh/128f2932f1e2ca53e149c533cbf82196/11.0.0_og-image.jpg"},"siteTwitterUsername":null,"header":{"openedLabel":"Close","hoveringLabel":"Menu","linksCollection":{"items":[{"title":"Home","description":null,"url":null,"page":{"slug":"index"}},{"title":"Vision","description":null,"url":null,"page":{"slug":"vision"}},{"title":"Journey","description":null,"url":null,"page":{"slug":"journey"}},{"title":"Thinking","description":null,"url":null,"page":{"slug":"thinking"}},{"title":"Technology","description":null,"url":null,"page":{"slug":"technology"}},{"title":"Join us","description":null,"url":null,"page":{"slug":"join-us"}},{"title":"Team","description":null,"url":null,"page":{"slug":"team"}}]},"subLinksCollection":{"items":[{"title":"Connect","description":null,"url":null,"page":{"slug":"connect"}},{"title":"Google","description":null,"url":"https://about.google/","page":null},{"title":"Alphabet","description":null,"url":"https://abc.xyz/","page":null},{"title":"Privacy \u0026 Terms","description":null,"url":"https://policies.google.com","page":null}]},"socialsCollection":{"items":[{"url":"https://www.linkedin.com/company/everydayrobots/","platform":"Linkedin"}]},"media":{"sys":{"id":"6OEqGLyTLUWPlAUxPaH1A5"},"title":"Menu image","fileName":"0.0_menu.jpg","contentType":"image/jpeg","width":720,"height":1200,"url":"https://images.ctfassets.net/1ejv5e8uweut/6OEqGLyTLUWPlAUxPaH1A5/1a18dfeea5078e34d67b8e3c87e32226/0.0_menu.jpg"},"subNavBackToTopLabel":"Back To Top"},"footer":{"discoverNextHeading":"Discover next","copyright":"Copyright 2022 X Development LLC. All rights reserved.","linksCollection":{"items":[{"title":"Home","description":null,"url":null,"page":{"slug":"index"}},{"title":"Journey","description":null,"url":null,"page":{"slug":"journey"}},{"title":"Technology","description":null,"url":null,"page":{"slug":"technology"}},{"title":"Team","description":null,"url":null,"page":{"slug":"team"}},{"title":"Vision","description":null,"url":null,"page":{"slug":"vision"}},{"title":"Thinking","description":null,"url":null,"page":{"slug":"thinking"}},{"title":"Join us","description":null,"url":null,"page":{"slug":"join-us"}},{"title":"Connect","description":null,"url":null,"page":{"slug":"connect"}},{"title":"Privacy \u0026 Terms","description":null,"url":"https://policies.google.com","page":null},{"title":"Google","description":null,"url":"https://about.google/","page":null},{"title":"Alphabet","description":null,"url":"https://abc.xyz/","page":null}]},"socialsCollection":{"items":[{"url":"https://www.linkedin.com/company/everydayrobots/","platform":"Linkedin"}]}},"articlePageSize":12,"articleHeaderLabel":"Thinking","articleFootnotesHeader":"Links","articleTopicsHeader":"Topics","relatedArticlesHeader":"More in [topic]","youTubeChapterCurrentHeading":"Chapter [index]","youTubeChapterPrologueHeading":"Prologue","youTubePlayVideoCopy":"[duration] - Play video","usersPrefix":"by","fieldRequiredErrorLabel":"Field required","preview":false},"article":{"slug":"efficiently-initializing-reinforcement-learning-with-prior-policies","topicsCollection":{"items":[{"title":"News","slug":"news"},{"title":"Research","slug":"research"}]},"relatedTopic":null,"title":"Efficiently Initializing Reinforcement Learning With Prior Policies","media":{"sys":{"id":"4hO9HJ5AyTzOSwQlzIEnky"},"title":"Robot sorting in real and sim ","fileName":"20210722-DSCF0126Peter-Prato (2).jpg","contentType":"image/jpeg","width":2000,"height":1500,"url":"https://images.ctfassets.net/1ejv5e8uweut/4hO9HJ5AyTzOSwQlzIEnky/b86362c044cc324535fb7e1112c10b07/20210722-DSCF0126Peter-Prato__2_.jpg"},"authorsCollection":{"items":[{"name":"Ikechukwu Uchendu"},{"name":"Ted Xiao"}]},"publishDate":"2022-04-07T00:00:00.000-04:00","blocksCollection":{"items":[{"__typename":"BlockRichText","text":{"json":{"nodeType":"document","data":{},"content":[{"nodeType":"paragraph","content":[{"nodeType":"text","value":"This piece was first published on the ","marks":[{"type":"italic"}],"data":{}},{"nodeType":"entry-hyperlink","content":[{"nodeType":"text","value":"Google AI Blog","marks":[{"type":"italic"}],"data":{}}],"data":{"target":{"sys":{"id":"1ZLP5o63NPfXVSs6BLucCf","type":"Link","linkType":"Entry"}}}},{"nodeType":"text","value":".","marks":[{"type":"italic"}],"data":{}}],"data":{}},{"nodeType":"paragraph","content":[{"nodeType":"text","value":"","marks":[],"data":{}},{"nodeType":"entry-hyperlink","content":[{"nodeType":"text","value":"Reinforcement learning","marks":[],"data":{}}],"data":{"target":{"sys":{"id":"5Gzvj9LNPyUy7kg1qqp0lv","type":"Link","linkType":"Entry"}}}},{"nodeType":"text","value":" (RL) can be used to train a policy to perform a task via trial and error, but a major challenge in RL is learning policies from scratch in environments with hard exploration challenges. For example, consider the setting depicted in the door-binary-v0 environment from the ","marks":[],"data":{}},{"nodeType":"entry-hyperlink","content":[{"nodeType":"text","value":"adroit manipulation suite","marks":[],"data":{}}],"data":{"target":{"sys":{"id":"7GhQAwwUfFTEjojVsWuoXU","type":"Link","linkType":"Entry"}}}},{"nodeType":"text","value":", where an RL agent must control a hand in 3D space to open a door placed in front of it.","marks":[],"data":{}}],"data":{}}]},"links":{"entries":{"hyperlink":[{"sys":{"id":"1ZLP5o63NPfXVSs6BLucCf"},"title":"Google AI Blog Efficiently Initializing Reinforcement Learning With Prior Policies","description":null,"url":"https://ai.googleblog.com/2022/04/efficiently-initializing-reinforcement.html","page":null},{"sys":{"id":"7GhQAwwUfFTEjojVsWuoXU"},"title":"Androit manipulation suite ","description":null,"url":"https://github.com/aravindr93/hand_dapg/","page":null},{"sys":{"id":"5Gzvj9LNPyUy7kg1qqp0lv"},"title":"Reinforcement learning","description":"Reinforcement learning - Wikipedia","url":"https://en.wikipedia.org/wiki/Reinforcement_learning","page":null}],"inline":[]}}}},{"__typename":"BlockMedia","media":{"sys":{"id":"78TKfKvQakZj6kXpSxIvvS"},"title":" An RL agent must control a hand in 3D space to open a door placed in front of it. The agent receives a reward signal only when the door is completely open. ","fileName":"door-binary-v0_AdobeCreativeCloudExpress.mp4","contentType":"video/mp4","width":null,"height":null,"url":"https://videos.ctfassets.net/1ejv5e8uweut/78TKfKvQakZj6kXpSxIvvS/998e774eae6026b7e32edc93c26fb696/door-binary-v0_AdobeCreativeCloudExpress.mp4","description":"\nAn RL agent must control a hand in 3D space to open a door placed in front of it. The agent receives a reward signal only when the door is completely open. \n"},"id":null,"isAtTopOfPage":false},{"__typename":"BlockRichText","text":{"json":{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"Since the agent receives no intermediary rewards, it cannot measure how close it is to completing the task, and so must explore the space randomly until it eventually opens the door. Given how long the task takes and the precise control required, this is extremely unlikely.","nodeType":"text"}],"nodeType":"paragraph"},{"data":{},"content":[{"data":{},"marks":[],"value":"For tasks like this, we can avoid exploring the state space randomly by using prior information. This prior information helps the agent understand which states of the environment are good, and should be further explored. We could use offline data (i.e., data collected by human demonstrators, scripted policies, or other RL agents) to train a policy, then use it to initialize a new RL policy. In the case where we use neural networks to represent the policies, this would involve copying the pre-trained policy’s neural network over to the new RL policy. This procedure makes the new RL policy behave like the pre-trained policy. However, naïvely initializing a new RL policy like this often works poorly, especially for","nodeType":"text"},{"data":{"target":{"sys":{"id":"5cXFUdZ8m6KQF1DyQtkxid","type":"Link","linkType":"Entry"}}},"content":[{"data":{},"marks":[{"type":"underline"}],"value":" value-based RL","nodeType":"text"}],"nodeType":"entry-hyperlink"},{"data":{},"marks":[],"value":" methods, as shown below.","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"document"},"links":{"entries":{"hyperlink":[{"sys":{"id":"5cXFUdZ8m6KQF1DyQtkxid"},"title":"Value-based RL wiki page","description":null,"url":"https://en.wikipedia.org/wiki/Value_function","page":null}],"inline":[]}}}},{"__typename":"BlockMedia","media":{"sys":{"id":"5E6oGpSqVAcDPjYT7KjC4S"},"title":"Native Bootstrapping ","fileName":"naive_bootstrapping.png","contentType":"image/png","width":1074,"height":523,"url":"https://images.ctfassets.net/1ejv5e8uweut/5E6oGpSqVAcDPjYT7KjC4S/1f63607504188996b73ddde04ea40e96/naive_bootstrapping.png","description":"A policy is pre-trained on the antmaze-large-diverse-v0 D4RL environment with offline data (negative steps correspond to pre-training). We then use the policy to initialize actor-critic fine-tuning (positive steps starting from step 0) with this pre-trained policy as the initial actor. The critic is initialized randomly. The actor’s performance immediately drops and does not recover, as the untrained critic provides a poor learning signal and causes the good initial policy to be forgotten."},"id":null,"isAtTopOfPage":false},{"__typename":"BlockRichText","text":{"json":{"nodeType":"document","data":{},"content":[{"nodeType":"paragraph","content":[{"nodeType":"text","value":"With the above in mind, in “","marks":[],"data":{}},{"nodeType":"entry-hyperlink","content":[{"nodeType":"text","value":"Jump-Start Reinforcement Learning","marks":[{"type":"underline"}],"data":{}}],"data":{"target":{"sys":{"id":"6h0q4htCn8zRr2HvgEAX9Z","type":"Link","linkType":"Entry"}}}},{"nodeType":"text","value":"” (JSRL), we introduce a meta-algorithm that can use a pre-existing policy of any form to initialize any type of RL algorithm. JSRL uses two policies to learn tasks: a ","marks":[],"data":{}},{"nodeType":"text","value":"guide-policy","marks":[{"type":"italic"}],"data":{}},{"nodeType":"text","value":", and an ","marks":[],"data":{}},{"nodeType":"text","value":"exploration-policy","marks":[{"type":"italic"}],"data":{}},{"nodeType":"text","value":". The exploration-policy is an RL policy that is trained online with new experience that the agent collects from the environment, and the guide-policy is a pre-existing policy of any form that is not updated during online training. In this work, we focus on scenarios where the guide-policy is learned from demonstrations, but many other kinds of guide-policies can be used. JSRL creates a learning curriculum by rolling in the guide-policy, which is then followed by the self-improving exploration-policy, resulting in performance that compares to or improves on competitive IL+RL methods.","marks":[],"data":{}}],"data":{}},{"nodeType":"heading-4","content":[{"nodeType":"text","value":"The JSRL Approach","marks":[{"type":"bold"}],"data":{}}],"data":{}},{"nodeType":"paragraph","content":[{"nodeType":"text","value":"The guide-policy can take any form: it could be a scripted policy, a policy trained with RL, or even a live human demonstrator. The only requirements are that the guide-policy is reasonable (i.e., better than random exploration), and it can select actions based on observations of the environment. Ideally, the guide-policy can reach poor or medium performance in the environment, but cannot further improve itself with additional fine-tuning. JSRL then allows us to leverage the progress of this guide-policy to take the performance even higher. ","marks":[],"data":{}}],"data":{}},{"nodeType":"paragraph","content":[{"nodeType":"text","value":"At the beginning of training, we roll out the guide-policy for a fixed number of steps so that the agent is closer to goal states. The exploration-policy then takes over and continues acting in the environment to reach these goals. As the performance of the exploration-policy improves, we gradually reduce the number of steps that the guide-policy takes, until the exploration-policy takes over completely. This process creates a curriculum of starting states for the exploration-policy such that in each curriculum stage, it only needs to learn to reach the initial states of prior curriculum stages.","marks":[],"data":{}}],"data":{}}]},"links":{"entries":{"hyperlink":[{"sys":{"id":"6h0q4htCn8zRr2HvgEAX9Z"},"title":"Jump-start RL Learning Arxiv Paper","description":null,"url":"https://arxiv.org/abs/2204.02372","page":null}],"inline":[]}}}},{"__typename":"BlockMedia","media":{"sys":{"id":"53rQsCbW99wRQFq7bNjbAB"},"title":"Guide policy","fileName":"Guide policy.mp4","contentType":"video/mp4","width":null,"height":null,"url":"https://videos.ctfassets.net/1ejv5e8uweut/53rQsCbW99wRQFq7bNjbAB/1b17f791c6b6fca1fa883866ecf09d82/Guide_policy.mp4","description":"\nHere, the task is for the robot arm to pick up the blue block. The guide-policy can move the arm to the block, but it cannot pick it up. It controls the agent until it grips the block, then the exploration-policy takes over, eventually learning to pick up the block. As the exploration-policy improves, the guide-policy controls the agent less and less.\n"},"id":null,"isAtTopOfPage":false},{"__typename":"BlockRichText","text":{"json":{"nodeType":"document","data":{},"content":[{"nodeType":"heading-4","content":[{"nodeType":"text","value":"Comparison to IL+RL Baselines","marks":[{"type":"bold"}],"data":{}}],"data":{}},{"nodeType":"paragraph","content":[{"nodeType":"text","value":"Since JSRL can use a prior policy to initialize RL, a natural comparison would be to ","marks":[],"data":{}},{"nodeType":"entry-hyperlink","content":[{"nodeType":"text","value":"imitation","marks":[{"type":"underline"}],"data":{}}],"data":{"target":{"sys":{"id":"1esrOXozXLffjvyTqLvvAh","type":"Link","linkType":"Entry"}}}},{"nodeType":"text","value":" and reinforcement learning (IL+RL) methods that train on offline datasets, then fine-tune the pre-trained policies with new online experience. We show how JSRL compares to competitive IL+RL methods on the ","marks":[],"data":{}},{"nodeType":"entry-hyperlink","content":[{"nodeType":"text","value":"D4RL","marks":[{"type":"underline"}],"data":{}}],"data":{"target":{"sys":{"id":"3xhtRehLFIBmLqHU7A3tiH","type":"Link","linkType":"Entry"}}}},{"nodeType":"text","value":" benchmark tasks. These tasks include simulated robotic control environments, along with datasets of offline data from human demonstrators, planners, and other learned policies. Out of the ","marks":[],"data":{}},{"nodeType":"entry-hyperlink","content":[{"nodeType":"text","value":"D4RL","marks":[{"type":"underline"}],"data":{}}],"data":{"target":{"sys":{"id":"3xhtRehLFIBmLqHU7A3tiH","type":"Link","linkType":"Entry"}}}},{"nodeType":"text","value":" tasks, we focus on the difficult ant maze and ","marks":[],"data":{}},{"nodeType":"entry-hyperlink","content":[{"nodeType":"text","value":"adroit dexterous manipulation","marks":[{"type":"underline"}],"data":{}}],"data":{"target":{"sys":{"id":"7GhQAwwUfFTEjojVsWuoXU","type":"Link","linkType":"Entry"}}}},{"nodeType":"text","value":" environments.","marks":[],"data":{}}],"data":{}}]},"links":{"entries":{"hyperlink":[{"sys":{"id":"7GhQAwwUfFTEjojVsWuoXU"},"title":"Androit manipulation suite ","description":null,"url":"https://github.com/aravindr93/hand_dapg/","page":null},{"sys":{"id":"3xhtRehLFIBmLqHU7A3tiH"},"title":"D45L Github page","description":null,"url":"https://github.com/rail-berkeley/d4rl","page":null},{"sys":{"id":"1esrOXozXLffjvyTqLvvAh"},"title":"An Algorithmic Perspective on Imitation Learning","description":"An Algorithmic Perspective on Imitation Learning - arXiv","url":"https://arxiv.org/pdf/1811.06711.pdf","page":null}],"inline":[]}}}},{"__typename":"BlockMedia","media":{"sys":{"id":"1L0W8IW7nQqHj4hDRtNMEh"},"title":"Ant Maze ","fileName":"Screen Shot 2022-04-08 at 1.49.15 PM.png","contentType":"image/png","width":642,"height":330,"url":"https://images.ctfassets.net/1ejv5e8uweut/1L0W8IW7nQqHj4hDRtNMEh/36ef4474949fee319af8c6b74eb9618d/Screen_Shot_2022-04-08_at_1.49.15_PM.png","description":"Example ant maze (left) and adroit dexterous manipulation (right) environments."},"id":null,"isAtTopOfPage":false},{"__typename":"BlockRichText","text":{"json":{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"For each experiment, we train on an offline dataset and then run online fine-tuning. We compare against algorithms designed specifically for each setting, which include ","nodeType":"text"},{"data":{"target":{"sys":{"id":"4geatw3RECiTIeARgitTsg","type":"Link","linkType":"Entry"}}},"content":[{"data":{},"marks":[{"type":"underline"}],"value":"AWAC","nodeType":"text"}],"nodeType":"entry-hyperlink"},{"data":{},"marks":[],"value":", ","nodeType":"text"},{"data":{"target":{"sys":{"id":"5EH1rAEXr5QjqKxWx5lAZr","type":"Link","linkType":"Entry"}}},"content":[{"data":{},"marks":[{"type":"underline"}],"value":"IQL","nodeType":"text"}],"nodeType":"entry-hyperlink"},{"data":{},"marks":[],"value":", ","nodeType":"text"},{"data":{"target":{"sys":{"id":"1Zhyiq6sSEW95iHMNUY0RE","type":"Link","linkType":"Entry"}}},"content":[{"data":{},"marks":[{"type":"underline"}],"value":"CQL","nodeType":"text"}],"nodeType":"entry-hyperlink"},{"data":{},"marks":[],"value":", and ","nodeType":"text"},{"data":{"target":{"sys":{"id":"MHxoeGGc9QDEyMfrPqPd0","type":"Link","linkType":"Entry"}}},"content":[{"data":{},"marks":[{"type":"underline"}],"value":"behavioral cloning","nodeType":"text"}],"nodeType":"entry-hyperlink"},{"data":{},"marks":[],"value":". While JSRL can be used in combination with any initial guide-policy or fine-tuning algorithm, we use our strongest baseline, IQL, as a pre-trained guide and for fine-tuning. The full D4RL dataset includes one million offline transitions for each ant maze task. Each transition is a sequence of format (S, A, R, S’) which specifies what state the agent started in (S), the action the agent took (A), the reward the agent received (R), and the state the agent ended up in (S’) after taking action A. We find that JSRL performs well with as few as ten thousand offline transitions.","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"document"},"links":{"entries":{"hyperlink":[{"sys":{"id":"MHxoeGGc9QDEyMfrPqPd0"},"title":"Behavioral Cloning ","description":null,"url":"https://link.springer.com/referenceworkentry/10.1007/978-0-387-30164-8_69","page":null},{"sys":{"id":"1Zhyiq6sSEW95iHMNUY0RE"},"title":"CQL ","description":null,"url":"https://sites.google.com/corp/view/cql-offline-rl","page":null},{"sys":{"id":"5EH1rAEXr5QjqKxWx5lAZr"},"title":"IQL Git hub","description":null,"url":"https://github.com/ikostrikov/implicit_q_learning","page":null},{"sys":{"id":"4geatw3RECiTIeARgitTsg"},"title":"AWAC: Accelerating Online Reinforcement Learning with Offline Datasets","description":null,"url":"https://bair.berkeley.edu/blog/2020/09/10/awac/","page":null}],"inline":[]}}}},{"__typename":"BlockMedia","media":{"sys":{"id":"4tu6c9gU14Q0L1RmTAgHcK"},"title":"10,000 offline transactions ","fileName":"antmaze_10k.png","contentType":"image/png","width":1074,"height":523,"url":"https://images.ctfassets.net/1ejv5e8uweut/4tu6c9gU14Q0L1RmTAgHcK/472ca3d6529a52a40197215d90ab1534/antmaze_10k.png","description":"10,000 offline transactions "},"id":null,"isAtTopOfPage":false},{"__typename":"BlockMedia","media":{"sys":{"id":"7GRLg797jFmxm8gBJhcjmp"},"title":"Average score (max=100) on the antmaze-medium-diverse-v0 environment from the D4RL benchmark suite. JSRL can improve even with limited access to offline transitions. ","fileName":"antmaze_100k.png","contentType":"image/png","width":1074,"height":523,"url":"https://images.ctfassets.net/1ejv5e8uweut/7GRLg797jFmxm8gBJhcjmp/518d75416926237b199ee58e958bf3bd/antmaze_100k.png","description":"Average score (max=100) on the antmaze-medium-diverse-v0 environment from the D4RL benchmark suite. JSRL can improve even with limited access to offline transitions. "},"id":null,"isAtTopOfPage":false},{"__typename":"BlockRichText","text":{"json":{"nodeType":"document","data":{},"content":[{"nodeType":"heading-4","content":[{"nodeType":"text","value":"Vision-Based Robotic Tasks","marks":[{"type":"bold"}],"data":{}}],"data":{}},{"nodeType":"paragraph","content":[{"nodeType":"text","value":"Utilizing offline data is especially challenging in complex tasks such as vision-based robotic manipulation due to the ","marks":[],"data":{}},{"nodeType":"entry-hyperlink","content":[{"nodeType":"text","value":"curse of dimensionality","marks":[{"type":"underline"}],"data":{}}],"data":{"target":{"sys":{"id":"4cjAnaVVoaDoarNy239Q5f","type":"Link","linkType":"Entry"}}}},{"nodeType":"text","value":". The high dimensionality of both the continuous-control action space and the pixel-based state space present scaling challenges for IL+RL methods in terms of the amount of data required to learn good policies. To study how JSRL scales to such settings, we focus on two difficult simulated robotic manipulation tasks: ","marks":[],"data":{}},{"nodeType":"text","value":"indiscriminate grasping","marks":[{"type":"italic"}],"data":{}},{"nodeType":"text","value":" (i.e., lifting any object) and ","marks":[],"data":{}},{"nodeType":"text","value":"instance grasping","marks":[{"type":"italic"}],"data":{}},{"nodeType":"text","value":" (i.e., lifting a specific target object).","marks":[],"data":{}}],"data":{}}]},"links":{"entries":{"hyperlink":[{"sys":{"id":"4cjAnaVVoaDoarNy239Q5f"},"title":"Curse of dimensionality ","description":null,"url":"https://en.wikipedia.org/wiki/Curse_of_dimensionality","page":null}],"inline":[]}}}},{"__typename":"BlockMedia","media":{"sys":{"id":"1Df9TTGVrD4nL5Ex1CElgi"},"title":"A simulated robot arm is placed in front of a table with various categories of objects. When the robot lifts any object, a sparse reward is given for the indiscriminate grasping task. For the instance grasping task, a sparse reward is only given when a specific target object is grasped.","fileName":"sorty_sim.png","contentType":"image/png","width":472,"height":390,"url":"https://images.ctfassets.net/1ejv5e8uweut/1Df9TTGVrD4nL5Ex1CElgi/7c50ac5b99931fbd691caedc4a973fad/sorty_sim.png","description":"A simulated robot arm is placed in front of a table with various categories of objects. When the robot lifts any object, a sparse reward is given for the indiscriminate grasping task. For the instance grasping task, a sparse reward is only given when a specific target object is grasped."},"id":null,"isAtTopOfPage":false},{"__typename":"BlockRichText","text":{"json":{"data":{},"content":[{"data":{},"content":[{"data":{},"marks":[],"value":"We compare JSRL against methods that are able to scale to complex vision-based robotics settings, such as ","nodeType":"text"},{"data":{"target":{"sys":{"id":"Bgfe1EIwd8GTCbtCOtqrH","type":"Link","linkType":"Entry"}}},"content":[{"data":{},"marks":[{"type":"underline"}],"value":"QT-Opt","nodeType":"text"}],"nodeType":"entry-hyperlink"},{"data":{},"marks":[],"value":" and ","nodeType":"text"},{"data":{"target":{"sys":{"id":"2h48LD7bVfIevoEmtH6O3u","type":"Link","linkType":"Entry"}}},"content":[{"data":{},"marks":[{"type":"underline"}],"value":"AW-Opt","nodeType":"text"}],"nodeType":"entry-hyperlink"},{"data":{},"marks":[],"value":". Each method has access to the same offline dataset of successful demonstrations and is allowed to run online fine-tuning for up to 100,000 steps.","nodeType":"text"}],"nodeType":"paragraph"},{"data":{},"content":[{"data":{},"marks":[],"value":"In these experiments, we use behavioral cloning as a guide-policy and combine JSRL with QT-Opt for fine-tuning. The combination of QT-Opt+JSRL improves faster than all other methods while achieving the highest success rate. ","nodeType":"text"}],"nodeType":"paragraph"}],"nodeType":"document"},"links":{"entries":{"hyperlink":[{"sys":{"id":"2h48LD7bVfIevoEmtH6O3u"},"title":"AW-Opt: Learning Robotic Skills with Imitation and Reinforcement at Scale - OpenReview","description":"AW-Opt: Learning Robotic Skills with Imitation and Reinforcement at Scale","url":"https://openreview.net/forum?id=xwEaXgFa0MR","page":null},{"sys":{"id":"Bgfe1EIwd8GTCbtCOtqrH"},"title":"QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation","description":"QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation - arXiv","url":"https://arxiv.org/abs/1806.10293","page":null}],"inline":[]}}}},{"__typename":"BlockMedia","media":{"sys":{"id":"72HZcMeKwPBrMvxEzfNrOu"},"title":"Mean grasping success for indiscriminate and instance grasping environments using 2k successful demonstrations. ","fileName":"ssorty_2k.png","contentType":"image/png","width":1080,"height":523,"url":"https://images.ctfassets.net/1ejv5e8uweut/72HZcMeKwPBrMvxEzfNrOu/d625061c3b3718d03637747cf56a9b39/ssorty_2k.png","description":"Mean grasping success for indiscriminate and instance grasping environments using 2k successful demonstrations. \n"},"id":null,"isAtTopOfPage":false},{"__typename":"BlockMedia","media":{"sys":{"id":"4dwViNH0sCP3jPHYj6ergk"},"title":"Mean grasping success for indiscriminate grasping environments using 2k successful demonstrations. ","fileName":"isorty_2k.png","contentType":"image/png","width":1080,"height":523,"url":"https://images.ctfassets.net/1ejv5e8uweut/4dwViNH0sCP3jPHYj6ergk/049db5e0797195ffbdd3fbc518298aa4/isorty_2k.png","description":"Mean grasping success for indiscriminate grasping environments using 2k successful demonstrations. "},"id":null,"isAtTopOfPage":false},{"__typename":"BlockRichText","text":{"json":{"nodeType":"document","data":{},"content":[{"nodeType":"heading-4","content":[{"nodeType":"text","value":"Conclusion","marks":[{"type":"bold"}],"data":{}}],"data":{}},{"nodeType":"paragraph","content":[{"nodeType":"text","value":"We proposed JSRL, a method for leveraging a prior policy of any form to improve exploration for initializing RL tasks. Our algorithm creates a learning curriculum by rolling in a pre-existing guide-policy, which is then followed by the self-improving exploration-policy. The job of the exploration-policy is greatly simplified since it starts exploring from states closer to the goal. As the exploration-policy improves, the effect of the guide-policy diminishes, leading to a fully capable RL policy. In the future, we plan to apply JSRL to problems such as ","marks":[],"data":{}},{"nodeType":"entry-hyperlink","content":[{"nodeType":"text","value":"Sim2Real","marks":[{"type":"underline"}],"data":{}}],"data":{"target":{"sys":{"id":"4TGDb9Zgm0GX4NbxY01Oga","type":"Link","linkType":"Entry"}}}},{"nodeType":"text","value":", and explore how we can leverage multiple guide-policies to train RL agents.","marks":[],"data":{}}],"data":{}},{"nodeType":"paragraph","content":[{"nodeType":"text","value":"Acknowledgements","marks":[{"type":"bold"}],"data":{}},{"nodeType":"text","value":"\n","marks":[],"data":{}},{"nodeType":"text","value":"This work would not have been possible without Ikechukwu Uchendu, Ted Xiao, Yao Lu, Banghua Zhu, Mengyuan Yan, Joséphine Simon, Matthew Bennice, Chuyuan Fu, Cong Ma, Jiantao Jiao, Sergey Levine, and Karol Hausman. Special thanks to Tom Small for creating the animations for this post.","marks":[{"type":"italic"}],"data":{}}],"data":{}},{"nodeType":"paragraph","content":[{"nodeType":"text","value":"","marks":[],"data":{}}],"data":{}}]},"links":{"entries":{"hyperlink":[{"sys":{"id":"4TGDb9Zgm0GX4NbxY01Oga"},"title":"Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: a Survey","description":null,"url":"https://arxiv.org/pdf/2009.13303.pdf","page":null}],"inline":[]}}}}]}},"relatedArticles":null,"slug":"efficiently-initializing-reinforcement-learning-with-prior-policies"},"__N_SSG":true},"page":"/thinking/[slug]","query":{"slug":"efficiently-initializing-reinforcement-learning-with-prior-policies"},"buildId":"ZF09WpqHefixs7Zvyw-nn","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body>
<!-- Mirrored from everydayrobots.com/thinking/efficiently-initializing-reinforcement-learning-with-prior-policies by HTTrack Website Copier/3.x [XR&CO'2014], Mon, 16 May 2022 06:47:12 GMT -->
</html>